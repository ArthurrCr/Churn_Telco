{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta.boruta_py import BorutaPy # boruta requer numpy 1.23.1 ou abaixo\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento dos dados\n",
    "dataset = pd.read_csv('../data/WA_Fn-UseC_-Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter TotalCharges para float\n",
    "dataset['TotalCharges'] = pd.to_numeric(dataset['TotalCharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID           0\n",
       "gender               0\n",
       "SeniorCitizen        0\n",
       "Partner              0\n",
       "Dependents           0\n",
       "tenure               0\n",
       "PhoneService         0\n",
       "MultipleLines        0\n",
       "InternetService      0\n",
       "OnlineSecurity       0\n",
       "OnlineBackup         0\n",
       "DeviceProtection     0\n",
       "TechSupport          0\n",
       "StreamingTV          0\n",
       "StreamingMovies      0\n",
       "Contract             0\n",
       "PaperlessBilling     0\n",
       "PaymentMethod        0\n",
       "MonthlyCharges       0\n",
       "TotalCharges        11\n",
       "Churn                0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verificar nan em dataset\n",
    "display(dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover a coluna 'customerID'\n",
    "dataset.drop('customerID', axis=1, inplace=True)\n",
    "\n",
    "# Selecionar colunas categóricas, mantendo as colunas do tipo int e float no DataFrame\n",
    "categorical_cols = dataset.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Criar um DataFrame com as colunas categóricas aplicando label encoding\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "dataset_dummies = dataset.copy()\n",
    "for col in categorical_cols:\n",
    "    dataset_dummies[col] = label_encoder.fit_transform(dataset[col])\n",
    "\n",
    "# Separar as features e o target\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(dataset_dummies.drop('TotalCharges', axis=1))  # remove 'TotalCharges' from the features\n",
    "\n",
    "# Após a normalização, a coluna 'TotalCharges' é adicionada de volta ao array de features\n",
    "features_scaled = np.column_stack((features_scaled, dataset_dummies['TotalCharges']))\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=10) # Usa o KNN para preencher os valores faltantes\n",
    "features_imputed = imputer.fit_transform(features_scaled)\n",
    "\n",
    "# Adicionar 'TotalCharges' como última coluna\n",
    "dataset['TotalCharges'] = features_imputed[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure',\n",
       "       'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
       "       'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
       "       'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod',\n",
       "       'MonthlyCharges', 'TotalCharges', 'Churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um DataFrame com as colunas categóricas aplicando label encoding\n",
    "dataset_dummies = dataset.copy()\n",
    "for col in categorical_cols:\n",
    "    dataset_dummies[col] = label_encoder.fit_transform(dataset[col])\n",
    "\n",
    "# Dividindo os dados em características e target\n",
    "X = dataset_dummies.drop(['Churn'], axis=1)  # Características\n",
    "y = dataset_dummies['Churn'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do modelo XGBoost\n",
    "xg_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    subsample=0.5,\n",
    "    colsample_bytree=0.5,\n",
    "    objective='binary:logistic',\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8099290780141843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87       511\n",
      "           1       0.70      0.54      0.61       194\n",
      "\n",
      "    accuracy                           0.81       705\n",
      "   macro avg       0.77      0.73      0.74       705\n",
      "weighted avg       0.80      0.81      0.80       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = xg_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               2560      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,929\n",
      "Trainable params: 12,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "nn_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.01)), \n",
    "    Dropout(0.3), \n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.3), \n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.3), \n",
    "    Dense(1, activation='sigmoid') \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "nn_model.compile(optimizer='adam',\n",
    "              loss= BinaryCrossentropy(from_logits=False), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "179/179 [==============================] - 2s 5ms/step - loss: 24.4683 - accuracy: 0.6324 - val_loss: 3.4133 - val_accuracy: 0.7650\n",
      "Epoch 2/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 4.7988 - accuracy: 0.6492 - val_loss: 1.4989 - val_accuracy: 0.7808\n",
      "Epoch 3/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 2.5646 - accuracy: 0.6669 - val_loss: 1.4617 - val_accuracy: 0.7618\n",
      "Epoch 4/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.8113 - accuracy: 0.7123 - val_loss: 1.3820 - val_accuracy: 0.7618\n",
      "Epoch 5/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.5123 - accuracy: 0.7202 - val_loss: 1.3396 - val_accuracy: 0.7618\n",
      "Epoch 6/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.4471 - accuracy: 0.7223 - val_loss: 1.3021 - val_accuracy: 0.7618\n",
      "Epoch 7/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.4189 - accuracy: 0.7277 - val_loss: 1.2870 - val_accuracy: 0.7618\n",
      "Epoch 8/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.3624 - accuracy: 0.7267 - val_loss: 1.2638 - val_accuracy: 0.7618\n",
      "Epoch 9/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.3364 - accuracy: 0.7286 - val_loss: 1.2297 - val_accuracy: 0.7618\n",
      "Epoch 10/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.2816 - accuracy: 0.7295 - val_loss: 1.2048 - val_accuracy: 0.7618\n",
      "Epoch 11/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.2436 - accuracy: 0.7302 - val_loss: 1.1956 - val_accuracy: 0.7618\n",
      "Epoch 12/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.2270 - accuracy: 0.7309 - val_loss: 1.1578 - val_accuracy: 0.7618\n",
      "Epoch 13/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.1832 - accuracy: 0.7323 - val_loss: 1.1342 - val_accuracy: 0.7618\n",
      "Epoch 14/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.1947 - accuracy: 0.7295 - val_loss: 1.1222 - val_accuracy: 0.7618\n",
      "Epoch 15/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.1631 - accuracy: 0.7307 - val_loss: 1.0880 - val_accuracy: 0.7618\n",
      "Epoch 16/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.1139 - accuracy: 0.7323 - val_loss: 1.0659 - val_accuracy: 0.7618\n",
      "Epoch 17/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.0914 - accuracy: 0.7311 - val_loss: 1.0520 - val_accuracy: 0.7618\n",
      "Epoch 18/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.0671 - accuracy: 0.7311 - val_loss: 1.0235 - val_accuracy: 0.7618\n",
      "Epoch 19/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.0432 - accuracy: 0.7318 - val_loss: 1.0030 - val_accuracy: 0.7618\n",
      "Epoch 20/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.0212 - accuracy: 0.7323 - val_loss: 0.9757 - val_accuracy: 0.7618\n",
      "Epoch 21/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.9982 - accuracy: 0.7321 - val_loss: 0.9656 - val_accuracy: 0.7618\n",
      "Epoch 22/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.9705 - accuracy: 0.7325 - val_loss: 0.9304 - val_accuracy: 0.7618\n",
      "Epoch 23/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.9492 - accuracy: 0.7318 - val_loss: 0.9127 - val_accuracy: 0.7618\n",
      "Epoch 24/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.9302 - accuracy: 0.7316 - val_loss: 0.8983 - val_accuracy: 0.7618\n",
      "Epoch 25/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.9046 - accuracy: 0.7323 - val_loss: 0.8671 - val_accuracy: 0.7618\n",
      "Epoch 26/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.8811 - accuracy: 0.7326 - val_loss: 0.8530 - val_accuracy: 0.7618\n",
      "Epoch 27/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.8629 - accuracy: 0.7321 - val_loss: 0.8349 - val_accuracy: 0.7618\n",
      "Epoch 28/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.8461 - accuracy: 0.7325 - val_loss: 0.8097 - val_accuracy: 0.7618\n",
      "Epoch 29/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.8270 - accuracy: 0.7318 - val_loss: 0.7895 - val_accuracy: 0.7618\n",
      "Epoch 30/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.8027 - accuracy: 0.7325 - val_loss: 0.7683 - val_accuracy: 0.7618\n",
      "Epoch 31/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.7814 - accuracy: 0.7325 - val_loss: 0.7495 - val_accuracy: 0.7618\n",
      "Epoch 32/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.7664 - accuracy: 0.7330 - val_loss: 0.7336 - val_accuracy: 0.7618\n",
      "Epoch 33/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.7527 - accuracy: 0.7323 - val_loss: 0.7227 - val_accuracy: 0.7618\n",
      "Epoch 34/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.7342 - accuracy: 0.7330 - val_loss: 0.7018 - val_accuracy: 0.7618\n",
      "Epoch 35/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.7198 - accuracy: 0.7321 - val_loss: 0.6886 - val_accuracy: 0.7618\n",
      "Epoch 36/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.7089 - accuracy: 0.7321 - val_loss: 0.6736 - val_accuracy: 0.7618\n",
      "Epoch 37/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6910 - accuracy: 0.7328 - val_loss: 0.6600 - val_accuracy: 0.7618\n",
      "Epoch 38/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6764 - accuracy: 0.7326 - val_loss: 0.6475 - val_accuracy: 0.7618\n",
      "Epoch 39/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6696 - accuracy: 0.7328 - val_loss: 0.6362 - val_accuracy: 0.7618\n",
      "Epoch 40/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6570 - accuracy: 0.7325 - val_loss: 0.6345 - val_accuracy: 0.7618\n",
      "Epoch 41/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6455 - accuracy: 0.7325 - val_loss: 0.6163 - val_accuracy: 0.7618\n",
      "Epoch 42/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6383 - accuracy: 0.7325 - val_loss: 0.6128 - val_accuracy: 0.7618\n",
      "Epoch 43/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6292 - accuracy: 0.7323 - val_loss: 0.6007 - val_accuracy: 0.7618\n",
      "Epoch 44/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6205 - accuracy: 0.7323 - val_loss: 0.5927 - val_accuracy: 0.7618\n",
      "Epoch 45/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6133 - accuracy: 0.7325 - val_loss: 0.5865 - val_accuracy: 0.7618\n",
      "Epoch 46/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6063 - accuracy: 0.7328 - val_loss: 0.5837 - val_accuracy: 0.7618\n",
      "Epoch 47/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6012 - accuracy: 0.7326 - val_loss: 0.5770 - val_accuracy: 0.7618\n",
      "Epoch 48/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5956 - accuracy: 0.7326 - val_loss: 0.5697 - val_accuracy: 0.7618\n",
      "Epoch 49/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5888 - accuracy: 0.7328 - val_loss: 0.5660 - val_accuracy: 0.7618\n",
      "Epoch 50/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5860 - accuracy: 0.7328 - val_loss: 0.5617 - val_accuracy: 0.7618\n",
      "Epoch 51/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5823 - accuracy: 0.7325 - val_loss: 0.5587 - val_accuracy: 0.7618\n",
      "Epoch 52/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5791 - accuracy: 0.7325 - val_loss: 0.5572 - val_accuracy: 0.7618\n",
      "Epoch 53/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5796 - accuracy: 0.7326 - val_loss: 0.5579 - val_accuracy: 0.7618\n",
      "Epoch 54/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5732 - accuracy: 0.7328 - val_loss: 0.5518 - val_accuracy: 0.7618\n",
      "Epoch 55/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5765 - accuracy: 0.7326 - val_loss: 0.5513 - val_accuracy: 0.7618\n",
      "Epoch 56/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5739 - accuracy: 0.7328 - val_loss: 0.5492 - val_accuracy: 0.7618\n",
      "Epoch 57/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5694 - accuracy: 0.7328 - val_loss: 0.5487 - val_accuracy: 0.7618\n",
      "Epoch 58/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5695 - accuracy: 0.7328 - val_loss: 0.5488 - val_accuracy: 0.7618\n",
      "Epoch 59/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5689 - accuracy: 0.7328 - val_loss: 0.5452 - val_accuracy: 0.7618\n",
      "Epoch 60/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5666 - accuracy: 0.7328 - val_loss: 0.5448 - val_accuracy: 0.7618\n",
      "Epoch 61/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5681 - accuracy: 0.7328 - val_loss: 0.5448 - val_accuracy: 0.7618\n",
      "Epoch 62/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5674 - accuracy: 0.7328 - val_loss: 0.5439 - val_accuracy: 0.7618\n",
      "Epoch 63/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5651 - accuracy: 0.7328 - val_loss: 0.5441 - val_accuracy: 0.7618\n",
      "Epoch 64/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5648 - accuracy: 0.7328 - val_loss: 0.5476 - val_accuracy: 0.7618\n",
      "Epoch 65/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5660 - accuracy: 0.7328 - val_loss: 0.5436 - val_accuracy: 0.7618\n",
      "Epoch 66/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5640 - accuracy: 0.7328 - val_loss: 0.5483 - val_accuracy: 0.7618\n",
      "Epoch 67/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5629 - accuracy: 0.7328 - val_loss: 0.5490 - val_accuracy: 0.7618\n",
      "Epoch 68/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5654 - accuracy: 0.7328 - val_loss: 0.5466 - val_accuracy: 0.7618\n",
      "Epoch 69/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5601 - accuracy: 0.7328 - val_loss: 0.5411 - val_accuracy: 0.7618\n",
      "Epoch 70/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5625 - accuracy: 0.7328 - val_loss: 0.5415 - val_accuracy: 0.7618\n",
      "Epoch 71/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5645 - accuracy: 0.7328 - val_loss: 0.5383 - val_accuracy: 0.7618\n",
      "Epoch 72/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5619 - accuracy: 0.7328 - val_loss: 0.5408 - val_accuracy: 0.7618\n",
      "Epoch 73/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5661 - accuracy: 0.7328 - val_loss: 0.5360 - val_accuracy: 0.7618\n",
      "Epoch 74/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5575 - accuracy: 0.7328 - val_loss: 0.5288 - val_accuracy: 0.7618\n",
      "Epoch 75/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5567 - accuracy: 0.7328 - val_loss: 0.5214 - val_accuracy: 0.7618\n",
      "Epoch 76/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5449 - accuracy: 0.7328 - val_loss: 0.4982 - val_accuracy: 0.7618\n",
      "Epoch 77/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5435 - accuracy: 0.7328 - val_loss: 0.5321 - val_accuracy: 0.7618\n",
      "Epoch 78/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5396 - accuracy: 0.7328 - val_loss: 0.5167 - val_accuracy: 0.7618\n",
      "Epoch 79/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5381 - accuracy: 0.7328 - val_loss: 0.4975 - val_accuracy: 0.7618\n",
      "Epoch 80/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5289 - accuracy: 0.7328 - val_loss: 0.4887 - val_accuracy: 0.7618\n",
      "Epoch 81/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5334 - accuracy: 0.7328 - val_loss: 0.4798 - val_accuracy: 0.7618\n",
      "Epoch 82/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5328 - accuracy: 0.7328 - val_loss: 0.4814 - val_accuracy: 0.7618\n",
      "Epoch 83/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5360 - accuracy: 0.7328 - val_loss: 0.4885 - val_accuracy: 0.7618\n",
      "Epoch 84/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5282 - accuracy: 0.7328 - val_loss: 0.4729 - val_accuracy: 0.7618\n",
      "Epoch 85/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5338 - accuracy: 0.7328 - val_loss: 0.4702 - val_accuracy: 0.7618\n",
      "Epoch 86/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5306 - accuracy: 0.7328 - val_loss: 0.4739 - val_accuracy: 0.7618\n",
      "Epoch 87/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5256 - accuracy: 0.7328 - val_loss: 0.4698 - val_accuracy: 0.7618\n",
      "Epoch 88/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5240 - accuracy: 0.7328 - val_loss: 0.4807 - val_accuracy: 0.7618\n",
      "Epoch 89/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5245 - accuracy: 0.7328 - val_loss: 0.4751 - val_accuracy: 0.7618\n",
      "Epoch 90/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5294 - accuracy: 0.7328 - val_loss: 0.4750 - val_accuracy: 0.7618\n",
      "Epoch 91/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5191 - accuracy: 0.7328 - val_loss: 0.4621 - val_accuracy: 0.7618\n",
      "Epoch 92/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5231 - accuracy: 0.7328 - val_loss: 0.4595 - val_accuracy: 0.7618\n",
      "Epoch 93/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5253 - accuracy: 0.7328 - val_loss: 0.4685 - val_accuracy: 0.7618\n",
      "Epoch 94/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5221 - accuracy: 0.7328 - val_loss: 0.4726 - val_accuracy: 0.7618\n",
      "Epoch 95/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5206 - accuracy: 0.7328 - val_loss: 0.4719 - val_accuracy: 0.7618\n",
      "Epoch 96/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5215 - accuracy: 0.7328 - val_loss: 0.4901 - val_accuracy: 0.7618\n",
      "Epoch 97/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5135 - accuracy: 0.7328 - val_loss: 0.4979 - val_accuracy: 0.7618\n",
      "Epoch 98/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5229 - accuracy: 0.7328 - val_loss: 0.4682 - val_accuracy: 0.7618\n",
      "Epoch 99/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5199 - accuracy: 0.7328 - val_loss: 0.4623 - val_accuracy: 0.7618\n",
      "Epoch 100/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5177 - accuracy: 0.7328 - val_loss: 0.4774 - val_accuracy: 0.7618\n",
      "Epoch 101/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5215 - accuracy: 0.7328 - val_loss: 0.4701 - val_accuracy: 0.7618\n",
      "Epoch 102/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5174 - accuracy: 0.7328 - val_loss: 0.4608 - val_accuracy: 0.7618\n",
      "Epoch 103/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5147 - accuracy: 0.7328 - val_loss: 0.4607 - val_accuracy: 0.7618\n",
      "Epoch 104/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5164 - accuracy: 0.7328 - val_loss: 0.4721 - val_accuracy: 0.7618\n",
      "Epoch 105/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5220 - accuracy: 0.7328 - val_loss: 0.4599 - val_accuracy: 0.7618\n",
      "Epoch 106/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5195 - accuracy: 0.7328 - val_loss: 0.4596 - val_accuracy: 0.7618\n",
      "Epoch 107/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5197 - accuracy: 0.7328 - val_loss: 0.4740 - val_accuracy: 0.7618\n",
      "Epoch 108/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5143 - accuracy: 0.7362 - val_loss: 0.4614 - val_accuracy: 0.7618\n",
      "Epoch 109/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5155 - accuracy: 0.7328 - val_loss: 0.4594 - val_accuracy: 0.7618\n",
      "Epoch 110/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5189 - accuracy: 0.7449 - val_loss: 0.4629 - val_accuracy: 0.7792\n",
      "Epoch 111/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5141 - accuracy: 0.7533 - val_loss: 0.4663 - val_accuracy: 0.7886\n",
      "Epoch 112/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5195 - accuracy: 0.7493 - val_loss: 0.4566 - val_accuracy: 0.7618\n",
      "Epoch 113/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5136 - accuracy: 0.7532 - val_loss: 0.4561 - val_accuracy: 0.7839\n",
      "Epoch 114/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5120 - accuracy: 0.7609 - val_loss: 0.4732 - val_accuracy: 0.7902\n",
      "Epoch 115/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5250 - accuracy: 0.7558 - val_loss: 0.4684 - val_accuracy: 0.7713\n",
      "Epoch 116/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5203 - accuracy: 0.7458 - val_loss: 0.4681 - val_accuracy: 0.7855\n",
      "Epoch 117/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5121 - accuracy: 0.7619 - val_loss: 0.4604 - val_accuracy: 0.7823\n",
      "Epoch 118/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5115 - accuracy: 0.7640 - val_loss: 0.4875 - val_accuracy: 0.7823\n",
      "Epoch 119/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5091 - accuracy: 0.7653 - val_loss: 0.4677 - val_accuracy: 0.7871\n",
      "Epoch 120/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5151 - accuracy: 0.7588 - val_loss: 0.4666 - val_accuracy: 0.7918\n",
      "Epoch 121/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5193 - accuracy: 0.7619 - val_loss: 0.4647 - val_accuracy: 0.7839\n",
      "Epoch 122/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5096 - accuracy: 0.7616 - val_loss: 0.4570 - val_accuracy: 0.7902\n",
      "Epoch 123/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5119 - accuracy: 0.7642 - val_loss: 0.4617 - val_accuracy: 0.7871\n",
      "Epoch 124/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5105 - accuracy: 0.7565 - val_loss: 0.4536 - val_accuracy: 0.7808\n",
      "Epoch 125/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5174 - accuracy: 0.7624 - val_loss: 0.4624 - val_accuracy: 0.7839\n",
      "Epoch 126/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5147 - accuracy: 0.7593 - val_loss: 0.4721 - val_accuracy: 0.7839\n",
      "Epoch 127/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5177 - accuracy: 0.7621 - val_loss: 0.4636 - val_accuracy: 0.7902\n",
      "Epoch 128/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5172 - accuracy: 0.7663 - val_loss: 0.4627 - val_accuracy: 0.7934\n",
      "Epoch 129/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5109 - accuracy: 0.7591 - val_loss: 0.4604 - val_accuracy: 0.7855\n",
      "Epoch 130/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5121 - accuracy: 0.7628 - val_loss: 0.4633 - val_accuracy: 0.7918\n",
      "Epoch 131/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5148 - accuracy: 0.7582 - val_loss: 0.4639 - val_accuracy: 0.7965\n",
      "Epoch 132/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5118 - accuracy: 0.7600 - val_loss: 0.4675 - val_accuracy: 0.7839\n",
      "Epoch 133/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5098 - accuracy: 0.7603 - val_loss: 0.4663 - val_accuracy: 0.7902\n",
      "Epoch 134/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5126 - accuracy: 0.7638 - val_loss: 0.4641 - val_accuracy: 0.7792\n",
      "Epoch 135/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5108 - accuracy: 0.7649 - val_loss: 0.4631 - val_accuracy: 0.7950\n",
      "Epoch 136/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5169 - accuracy: 0.7577 - val_loss: 0.4628 - val_accuracy: 0.7902\n",
      "Epoch 137/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5107 - accuracy: 0.7647 - val_loss: 0.4664 - val_accuracy: 0.7981\n",
      "Epoch 138/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5109 - accuracy: 0.7689 - val_loss: 0.4811 - val_accuracy: 0.7808\n",
      "Epoch 139/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5087 - accuracy: 0.7640 - val_loss: 0.4658 - val_accuracy: 0.7965\n",
      "Epoch 140/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.7607 - val_loss: 0.4618 - val_accuracy: 0.7950\n",
      "Epoch 141/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5098 - accuracy: 0.7549 - val_loss: 0.4709 - val_accuracy: 0.7981\n",
      "Epoch 142/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5105 - accuracy: 0.7640 - val_loss: 0.4574 - val_accuracy: 0.7950\n",
      "Epoch 143/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5117 - accuracy: 0.7626 - val_loss: 0.4673 - val_accuracy: 0.7792\n",
      "Epoch 144/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5100 - accuracy: 0.7605 - val_loss: 0.4538 - val_accuracy: 0.7965\n",
      "Epoch 145/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5091 - accuracy: 0.7584 - val_loss: 0.4614 - val_accuracy: 0.7934\n",
      "Epoch 146/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5103 - accuracy: 0.7649 - val_loss: 0.4607 - val_accuracy: 0.7871\n",
      "Epoch 147/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5116 - accuracy: 0.7644 - val_loss: 0.4599 - val_accuracy: 0.7902\n",
      "Epoch 148/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5209 - accuracy: 0.7610 - val_loss: 0.4843 - val_accuracy: 0.7902\n",
      "Epoch 149/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5127 - accuracy: 0.7654 - val_loss: 0.4605 - val_accuracy: 0.7950\n",
      "Epoch 150/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5148 - accuracy: 0.7556 - val_loss: 0.4615 - val_accuracy: 0.7839\n",
      "Epoch 151/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5064 - accuracy: 0.7637 - val_loss: 0.4653 - val_accuracy: 0.7997\n",
      "Epoch 152/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5064 - accuracy: 0.7591 - val_loss: 0.4552 - val_accuracy: 0.7902\n",
      "Epoch 153/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5115 - accuracy: 0.7553 - val_loss: 0.4581 - val_accuracy: 0.7855\n",
      "Epoch 154/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5103 - accuracy: 0.7653 - val_loss: 0.4627 - val_accuracy: 0.7965\n",
      "Epoch 155/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5124 - accuracy: 0.7631 - val_loss: 0.4561 - val_accuracy: 0.7871\n",
      "Epoch 156/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5113 - accuracy: 0.7637 - val_loss: 0.4627 - val_accuracy: 0.7981\n",
      "Epoch 157/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5146 - accuracy: 0.7684 - val_loss: 0.4638 - val_accuracy: 0.7965\n",
      "Epoch 158/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5145 - accuracy: 0.7621 - val_loss: 0.4580 - val_accuracy: 0.7902\n",
      "Epoch 159/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5137 - accuracy: 0.7640 - val_loss: 0.4577 - val_accuracy: 0.7997\n",
      "Epoch 160/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5073 - accuracy: 0.7660 - val_loss: 0.4611 - val_accuracy: 0.7997\n",
      "Epoch 161/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5078 - accuracy: 0.7630 - val_loss: 0.4623 - val_accuracy: 0.7918\n",
      "Epoch 162/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5088 - accuracy: 0.7621 - val_loss: 0.4667 - val_accuracy: 0.7855\n",
      "Epoch 163/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5116 - accuracy: 0.7688 - val_loss: 0.4599 - val_accuracy: 0.7918\n",
      "Epoch 164/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5104 - accuracy: 0.7584 - val_loss: 0.4651 - val_accuracy: 0.7950\n",
      "Epoch 165/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5130 - accuracy: 0.7623 - val_loss: 0.4602 - val_accuracy: 0.7839\n",
      "Epoch 166/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5106 - accuracy: 0.7649 - val_loss: 0.4542 - val_accuracy: 0.7918\n",
      "Epoch 167/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5085 - accuracy: 0.7623 - val_loss: 0.4618 - val_accuracy: 0.7902\n",
      "Epoch 168/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5077 - accuracy: 0.7661 - val_loss: 0.4565 - val_accuracy: 0.7997\n",
      "Epoch 169/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5187 - accuracy: 0.7560 - val_loss: 0.4559 - val_accuracy: 0.7713\n",
      "Epoch 170/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5073 - accuracy: 0.7635 - val_loss: 0.4523 - val_accuracy: 0.7965\n",
      "Epoch 171/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5047 - accuracy: 0.7642 - val_loss: 0.4649 - val_accuracy: 0.7918\n",
      "Epoch 172/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5124 - accuracy: 0.7605 - val_loss: 0.4568 - val_accuracy: 0.7918\n",
      "Epoch 173/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5128 - accuracy: 0.7656 - val_loss: 0.4673 - val_accuracy: 0.7902\n",
      "Epoch 174/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5143 - accuracy: 0.7609 - val_loss: 0.4674 - val_accuracy: 0.7934\n",
      "Epoch 175/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5027 - accuracy: 0.7665 - val_loss: 0.4633 - val_accuracy: 0.7855\n",
      "Epoch 176/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5091 - accuracy: 0.7619 - val_loss: 0.4565 - val_accuracy: 0.7981\n",
      "Epoch 177/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5065 - accuracy: 0.7637 - val_loss: 0.4606 - val_accuracy: 0.7918\n",
      "Epoch 178/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5159 - accuracy: 0.7635 - val_loss: 0.4655 - val_accuracy: 0.7918\n",
      "Epoch 179/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5104 - accuracy: 0.7598 - val_loss: 0.4596 - val_accuracy: 0.8044\n",
      "Epoch 180/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5142 - accuracy: 0.7565 - val_loss: 0.4618 - val_accuracy: 0.7871\n",
      "Epoch 181/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5102 - accuracy: 0.7626 - val_loss: 0.4496 - val_accuracy: 0.7918\n",
      "Epoch 182/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5172 - accuracy: 0.7596 - val_loss: 0.4567 - val_accuracy: 0.7981\n",
      "Epoch 183/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5076 - accuracy: 0.7665 - val_loss: 0.4470 - val_accuracy: 0.7997\n",
      "Epoch 184/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5154 - accuracy: 0.7575 - val_loss: 0.4676 - val_accuracy: 0.7965\n",
      "Epoch 185/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5113 - accuracy: 0.7556 - val_loss: 0.4528 - val_accuracy: 0.7871\n",
      "Epoch 186/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5176 - accuracy: 0.7616 - val_loss: 0.4556 - val_accuracy: 0.7839\n",
      "Epoch 187/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5076 - accuracy: 0.7589 - val_loss: 0.4629 - val_accuracy: 0.7934\n",
      "Epoch 188/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5113 - accuracy: 0.7624 - val_loss: 0.4688 - val_accuracy: 0.7965\n",
      "Epoch 189/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5093 - accuracy: 0.7602 - val_loss: 0.4650 - val_accuracy: 0.7997\n",
      "Epoch 190/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5048 - accuracy: 0.7630 - val_loss: 0.4576 - val_accuracy: 0.7997\n",
      "Epoch 191/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5066 - accuracy: 0.7660 - val_loss: 0.4601 - val_accuracy: 0.7934\n",
      "Epoch 192/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5057 - accuracy: 0.7646 - val_loss: 0.4532 - val_accuracy: 0.7950\n",
      "Epoch 193/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5082 - accuracy: 0.7684 - val_loss: 0.4521 - val_accuracy: 0.7934\n",
      "Epoch 194/200\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5076 - accuracy: 0.7684 - val_loss: 0.4651 - val_accuracy: 0.7934\n",
      "Epoch 195/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5110 - accuracy: 0.7637 - val_loss: 0.4492 - val_accuracy: 0.7950\n",
      "Epoch 196/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5028 - accuracy: 0.7654 - val_loss: 0.4608 - val_accuracy: 0.8013\n",
      "Epoch 197/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5089 - accuracy: 0.7628 - val_loss: 0.4722 - val_accuracy: 0.7886\n",
      "Epoch 198/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5164 - accuracy: 0.7638 - val_loss: 0.4687 - val_accuracy: 0.7902\n",
      "Epoch 199/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5089 - accuracy: 0.7579 - val_loss: 0.4515 - val_accuracy: 0.7918\n",
      "Epoch 200/200\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5053 - accuracy: 0.7596 - val_loss: 0.4632 - val_accuracy: 0.7855\n"
     ]
    }
   ],
   "source": [
    "history = nn_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotar a curva de perda de um modo\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.8085\n",
      "Test Accuracy: 0.8085106611251831\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "test_loss, test_acc = nn_model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.90      0.87       511\n",
      "         1.0       0.68      0.58      0.62       194\n",
      "\n",
      "    accuracy                           0.81       705\n",
      "   macro avg       0.76      0.74      0.75       705\n",
      "weighted avg       0.80      0.81      0.80       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "predictions = nn_model.predict(X_test)\n",
    "predictions = (predictions > 0.5).astype(int)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "nn_predictions = nn_model.predict(X_test)[:, 0]  # Retorna a probabilidade da classe positiva\n",
    "xgb_predictions = xg_model.predict_proba(X_test)[:, 1]  # Retorna a probabilidade da classe positiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Média das previsões\n",
    "final_predictions = (nn_predictions + xgb_predictions) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.8070921985815603\n"
     ]
    }
   ],
   "source": [
    "# Acurácia\n",
    "final_class_predictions = (final_predictions > 0.5).astype(int)\n",
    "print(\"Ensemble Accuracy:\", accuracy_score(y_test, final_class_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.93      0.87       511\n",
      "         1.0       0.72      0.49      0.58       194\n",
      "\n",
      "    accuracy                           0.81       705\n",
      "   macro avg       0.77      0.71      0.73       705\n",
      "weighted avg       0.80      0.81      0.79       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, final_class_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset desbalanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gráfico da Distribuição das classes em churn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Churn', data=dataset, palette='Paired', legend=False, hue='Churn')\n",
    "plt.title('Distribuição das classes em churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classificação desequilibrada é um problema comum no aprendizado de máquina, especialmente no domínio da classificação binária. Isso ocorre quando o conjunto de dados de treinamento tem uma distribuição desigual de classes, levando a um possível viés no modelo treinado. É importante abordar o desequilíbrio de classes para melhorar o desempenho do nosso modelo e garantir sua precisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modificando os Pesos na Função de Perda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A atribuição de pesos diferentes aos exemplos na função de perda pode ajudar a compensar o desequilíbrio. Isso significa dar maior importância aos exemplos da classe minoritária durante o treinamento do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`(y_train == 1).sum()`**: Este trecho conta quantas vezes a classe `1` aparece no conjunto de dados de treino. Isso é feito comparando cada elemento de `y_train` com `1` (verdadeiro onde a condição é atendida) e somando esses valores verdadeiros.\n",
    "\n",
    "**`(y_train == 0).sum()`**: Similarmente, este trecho conta quantas vezes a classe `0` aparece em `y_train`.\n",
    "\n",
    "**Divisão**: A divisão do número de exemplos da classe minoritária (1) pelo número de exemplos da classe majoritária(0) calcula um fator de peso. Esse peso será usado para equilibrar as classes, aumentando a importância das instâncias da classe minoritária durante o treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculando os pesos para cada classe\n",
    "weights = (y_train == 1).sum() / (1.0 * (y_train == 0).sum())\n",
    "\n",
    "xg_model = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.01, \n",
    "    max_depth=5,         # Quantidade de camadas, quanto mais camadas, mais complexo\n",
    "    subsample=0.7,       # Quantidade de amostras por árvore, quanto menos amostras, mais rápido\n",
    "    colsample_bytree=0.7,# Quantidade de colunas por árvore, quanto menos colunas, mais rápido\n",
    "    reg_alpha=0.01,      # Regularização L1\n",
    "    reg_lambda=1.0,      # Regularização L2\n",
    "    objective='binary:logistic',\n",
    "    random_state=42,\n",
    "    scale_pos_weight=weights\n",
    ")\n",
    "\n",
    "# Treinamento do modelo\n",
    "xg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7801418439716312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.98      0.87       511\n",
      "         1.0       0.85      0.24      0.38       194\n",
      "\n",
      "    accuracy                           0.78       705\n",
      "   macro avg       0.81      0.61      0.62       705\n",
      "weighted avg       0.80      0.78      0.73       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = xg_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step\n",
      "Ensemble Accuracy: 0.7659574468085106\n"
     ]
    }
   ],
   "source": [
    "nn_predictions = nn_model.predict(X_test)[:, 0]  # Retorna a probabilidade da classe positiva\n",
    "xgb_predictions = xg_model.predict_proba(X_test)[:, 1]  # Retorna a probabilidade da classe positiva\n",
    "\n",
    "# Média das previsões\n",
    "final_predictions = (nn_predictions + xgb_predictions) / 2\n",
    "\n",
    "# Acurácia\n",
    "final_class_predictions = (final_predictions > 0.5).astype(int)\n",
    "print(\"Ensemble Accuracy:\", accuracy_score(y_test, final_class_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.99      0.86       511\n",
      "         1.0       0.85      0.18      0.30       194\n",
      "\n",
      "    accuracy                           0.77       705\n",
      "   macro avg       0.81      0.58      0.58       705\n",
      "weighted avg       0.79      0.77      0.71       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, final_class_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise de Classe\n",
    "- **Classe 0 (Majoritária)**\n",
    "  - **Precisão**: 0.80. Isso indica que 80% das previsões para classe 0 estão corretas.\n",
    "  - **Recall**: 0.97. Significa que 97% das instâncias reais de classe 0 foram identificadas corretamente pelo modelo.\n",
    "  - **F1-Score**: 0.87. O F1-score é uma média harmônica de precisão e recall, e um valor de 0.87 sugere um bom equilíbrio entre precisão e recall para esta classe.\n",
    "  - **Suporte**: 511. Número total de casos reais da classe 0 no conjunto de teste.\n",
    "\n",
    "- **Classe 1 (Minoritária)**\n",
    "  - **Precisão**: 0.81. Isto sugere que 81% das previsões de classe 1 pelo modelo estão corretas.\n",
    "  - **Recall**: 0.35. Apenas 37% das instâncias reais de classe 1 foram identificadas corretamente, o que é bastante baixo.\n",
    "  - **F1-Score**: 0.49. Este valor mais baixo indica uma baixa eficácia do modelo em equilibrar a precisão e o recall para a classe minoritária.\n",
    "  - **Suporte**: 194. Número total de casos reais da classe 1 no conjunto de teste.\n",
    "\n",
    "### Análise Agregada\n",
    "- **Acurácia**: 0.80. Isso mostra que o modelo acertou 80% das vezes para todas as previsões feitas.\n",
    "- **Média Macro (avg)**:\n",
    "  - **Precisão**: 0.80. Média simples das precisões para ambas as classes.\n",
    "  - **Recall**: 0.66. Média simples dos recalls, afetada negativamente pelo baixo recall da classe 1.\n",
    "  - **F1-Score**: 0.68. Indica a média do F1-score, que também é puxada para baixo pela performance na classe 1.\n",
    "- **Média Ponderada (weighted avg)**:\n",
    "  - **Precisão**: 0.80. Considera o número de instâncias em cada classe, dando mais peso à classe 0.\n",
    "  - **Recall**: 0.80. Similar à precisão, ponderada pelo suporte.\n",
    "  - **F1-Score**: 0.77. F1-score ponderado que favorece a classe com mais suporte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponderar os pesos pode aumentar a precisão da classe minoritária, porém o recall e o f1-score podem ser afetados negativamente. Portanto, é importante encontrar um equilíbrio entre as métricas de avaliação para ambas as classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engenharia de Recursos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um tema comum em aprendizado de máquina é a seleção de boas características para maximizar o desempenho do modelo.\n",
    "\n",
    "Para conjuntos de dados estruturados, geralmente há dois passos para escolher um conjunto final de características:\n",
    "\n",
    "**Engenharia de características**: criação de novas características a partir dos dados (por exemplo, a partir do preço unitário e do volume total, talvez criar uma característica de receita total, igual ao preço vezes o volume).\n",
    "\n",
    "**Seleção de características**: de um conjunto de características $ p $, selecionar um subconjunto que mantenha (ou até melhore) o desempenho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engenharia de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receita total gerada por cada cliente ao longo do período de tempo (tenure) que ele permaneceu com a empresa.\n",
    "dataset['TotalRevenue'] = dataset['MonthlyCharges'] * dataset['tenure']\n",
    "\n",
    "# Contar quantos serviços o cliente tem\n",
    "services = ['PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "dataset['ActiveServices'] = dataset[services].apply(lambda x: x.str.contains('Sim').sum(), axis=1)\n",
    "\n",
    "# Normalizar a coluna 'tenure'\n",
    "dataset['NormalizedTenure'] = dataset['tenure'] / dataset['tenure'].max()\n",
    "\n",
    "# Criar uma coluna para identificar clientes idosos com parceiros\n",
    "dataset['SeniorCitizen_with_Partner'] = ((dataset['SeniorCitizen'] == 1) & (dataset['Partner'] == 'Sim')).astype(int)\n",
    "\n",
    "# Transformação temporal\n",
    "bins = [0, 12, 24, 36, 48, 60, 72]\n",
    "labels = ['0-12 months', '12-24 months', '24-36 months', '36-48 months', '48-60 months', '60-72 months']\n",
    "dataset['TenureGroup'] = pd.cut(dataset['tenure'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Combinação de Serviços\n",
    "dataset['Security_and_Backup'] = ((dataset['OnlineSecurity'] == 'Sim') & (dataset['OnlineBackup'] == 'Sim')).astype(int)\n",
    "\n",
    "# Análise de clusters\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(dataset[['MonthlyCharges', 'tenure']])\n",
    "dataset['CustomerCluster'] = kmeans.labels_\n",
    "\n",
    "# Comparar MonthlyCharges com TotalCharges para ver a consistência nas cobranças\n",
    "dataset['ChargesRatio'] = dataset['MonthlyCharges'] / (dataset['TotalCharges'].replace(' ', np.nan).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>TotalRevenue</th>\n",
       "      <th>ActiveServices</th>\n",
       "      <th>NormalizedTenure</th>\n",
       "      <th>SeniorCitizen_with_Partner</th>\n",
       "      <th>TenureGroup</th>\n",
       "      <th>Security_and_Backup</th>\n",
       "      <th>CustomerCluster</th>\n",
       "      <th>ChargesRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0</td>\n",
       "      <td>0-12 months</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>No</td>\n",
       "      <td>1936.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0</td>\n",
       "      <td>24-36 months</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.030140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>107.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0</td>\n",
       "      <td>0-12 months</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.497920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "      <td>1903.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>36-48 months</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>141.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0</td>\n",
       "      <td>0-12 months</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.466205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  Female              0     Yes         No       1           No   \n",
       "1    Male              0      No         No      34          Yes   \n",
       "2    Male              0      No         No       2          Yes   \n",
       "3    Male              0      No         No      45           No   \n",
       "4  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity OnlineBackup  ...  \\\n",
       "0  No phone service             DSL             No          Yes  ...   \n",
       "1                No             DSL            Yes           No  ...   \n",
       "2                No             DSL            Yes          Yes  ...   \n",
       "3  No phone service             DSL            Yes           No  ...   \n",
       "4                No     Fiber optic             No           No  ...   \n",
       "\n",
       "  TotalCharges Churn TotalRevenue ActiveServices NormalizedTenure  \\\n",
       "0        29.85    No        29.85              0         0.013889   \n",
       "1      1889.50    No      1936.30              0         0.472222   \n",
       "2       108.15   Yes       107.70              0         0.027778   \n",
       "3      1840.75    No      1903.50              0         0.625000   \n",
       "4       151.65   Yes       141.40              0         0.027778   \n",
       "\n",
       "  SeniorCitizen_with_Partner   TenureGroup  Security_and_Backup  \\\n",
       "0                          0   0-12 months                    0   \n",
       "1                          0  24-36 months                    0   \n",
       "2                          0   0-12 months                    0   \n",
       "3                          0  36-48 months                    0   \n",
       "4                          0   0-12 months                    0   \n",
       "\n",
       "   CustomerCluster ChargesRatio  \n",
       "0                2     1.000000  \n",
       "1                3     0.030140  \n",
       "2                2     0.497920  \n",
       "3                0     0.022980  \n",
       "4                1     0.466205  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar colunas categóricas, mantendo as colunas do tipo int e float no DataFrame\n",
    "categorical_cols = dataset.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "# Criar um DataFrame com as colunas categóricas aplicando label encoding\n",
    "dataset_dummies = dataset.copy()\n",
    "for col in categorical_cols:\n",
    "    dataset_dummies[col] = label_encoder.fit_transform(dataset[col])\n",
    "\n",
    "# Dividindo os dados em características e target\n",
    "X = dataset_dummies.drop(['Churn'], axis=1)  # Características\n",
    "y = dataset_dummies['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>...</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>TotalRevenue</th>\n",
       "      <th>ActiveServices</th>\n",
       "      <th>NormalizedTenure</th>\n",
       "      <th>SeniorCitizen_with_Partner</th>\n",
       "      <th>TenureGroup</th>\n",
       "      <th>Security_and_Backup</th>\n",
       "      <th>CustomerCluster</th>\n",
       "      <th>ChargesRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>1936.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.030140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>107.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.497920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>1903.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>141.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.466205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n",
       "0       0              0        1           0       1             0   \n",
       "1       1              0        0           0      34             1   \n",
       "2       1              0        0           0       2             1   \n",
       "3       1              0        0           0      45             0   \n",
       "4       0              0        0           0       2             1   \n",
       "\n",
       "   MultipleLines  InternetService  OnlineSecurity  OnlineBackup  ...  \\\n",
       "0              1                0               0             2  ...   \n",
       "1              0                0               2             0  ...   \n",
       "2              0                0               2             2  ...   \n",
       "3              1                0               2             0  ...   \n",
       "4              0                1               0             0  ...   \n",
       "\n",
       "   MonthlyCharges  TotalCharges  TotalRevenue  ActiveServices  \\\n",
       "0           29.85         29.85         29.85               0   \n",
       "1           56.95       1889.50       1936.30               0   \n",
       "2           53.85        108.15        107.70               0   \n",
       "3           42.30       1840.75       1903.50               0   \n",
       "4           70.70        151.65        141.40               0   \n",
       "\n",
       "   NormalizedTenure  SeniorCitizen_with_Partner  TenureGroup  \\\n",
       "0          0.013889                           0            0   \n",
       "1          0.472222                           0            2   \n",
       "2          0.027778                           0            0   \n",
       "3          0.625000                           0            3   \n",
       "4          0.027778                           0            0   \n",
       "\n",
       "   Security_and_Backup  CustomerCluster  ChargesRatio  \n",
       "0                    0                2      1.000000  \n",
       "1                    0                3      0.030140  \n",
       "2                    0                2      0.497920  \n",
       "3                    0                0      0.022980  \n",
       "4                    0                1      0.466205  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Há sempre características inúteis.** No caso da genômica, nem todos os genes estão ativos em um determinado momento - apenas uma fração deles contribui para o fenômeno de interesse. Em uma imagem de 800x600 de um gato, apenas uma pequena parte dos pixels descreverá realmente o gato, com o restante sendo objetos que não são de interesse. Da mesma forma, por mais rica que seja a informação das características de um indivíduo, apenas algumas contribuirão para seu comportamento de crédito.\n",
    "\n",
    "**Nosso objetivo é então encontrar maneiras sistemáticas de filtrar características inúteis.**\n",
    "\n",
    "É senso comum que, se você tem poucas características, seu modelo pode simplesmente não ter informações suficientes para ter um bom desempenho.\n",
    "\n",
    "Menos óbvio é que ter muitas características também pode ser problemático. Elas podem causar perda de desempenho devido a algumas razões relacionadas:\n",
    "\n",
    "- **Sobreajuste**: quanto mais características, mais difícil será para os pontos terem vizinhos próximos (a chamada maldição da dimensionalidade); você precisará de exponencialmente mais dados para cobrir o espaço de características de maneira significativa. Seu algoritmo é propenso a apenas sobreajustar;\n",
    "\n",
    "- **Ruído**: variáveis inúteis introduzem ruído que pode afetar o treinamento;\n",
    "\n",
    "- **Considerações de tempo/espaço**: quanto mais dimensões, mais memória seu computador precisa, e mais tempo levará para treinamento, otimização de hiperparâmetros, etc.\n",
    "\n",
    "Um dos métodos para seleção de características é o algoritmo Boruta, introduzido em 2010 por Kursa e Rudnicki. Ele se provou consistentemente como uma ferramenta poderosa para seleção direta de boas características em casos com milhares de características.\n",
    "\n",
    "De maneira simples, o Boruta funciona da seguinte forma: para cada característica, digamos `x1`, o Boruta cria uma cópia `x1_copy` (chamada de *sombra* pelos autores) e então mistura aleatoriamente os valores entre todos os pontos, criando ruído.\n",
    "\n",
    "Ele então ajusta um modelo (geralmente uma floresta aleatória) implementando um método de importância de características e analisa como a importância da característica original se compara às cópias ruidosas. Se elas forem significativamente diferentes, então `x1` é considerada valiosa e mantida; se não, significa que `x1` é basicamente ruído, e é removida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso de desequilíbrio de classes, **não use o upsampling**; em vez disso, faça uma validação cruzada com um **undersampling** da classe majoritária durante a seleção de características. Para o Boruta, use um **classificador base RandomForest com pesos**: `class_weight='balanced_subsample'`, e para o modelo final (treinado com todo o conjunto de treinamento usando as características selecionadas), veja se usar `class_weight` dá um resultado melhor do que não usá-lo.\n",
    "\n",
    "O parâmetro `perc` é um parâmetro extremamente importante introduzido na versão Python. Ele basicamente define quão \"flexível\" queremos ser com nossas características: `perc=100` é o mais rigoroso, e quanto mais próximo de 0, mais flexíveis somos ao permitir que características menos importantes sejam selecionadas.\n",
    "\n",
    "Usaremos o Boruta com florestas aleatórias.\n",
    "\n",
    "Como observado pelo próprio autor (em *Boruta para quem tem pressa*, Miron B. Kursa, 21 de maio de 2020), é importante que tenhamos um número suficiente de árvores:\n",
    "> \"Para conjuntos de dados com muitas características, a configuração padrão da fonte de importância provavelmente é insuficiente; no caso particular do Random Forest, o número de árvores muitas vezes não é grande o suficiente para permitir que os escores de importância se estabilizem, o que, por sua vez, muitas vezes leva a falsos negativos e resultados instáveis.\"\n",
    "\n",
    "Isso pode ser resolvido permitindo que o próprio Boruta identifique um número ótimo de árvores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição da Função\n",
    "A função `select_feature_boruta` aceita várias entradas:\n",
    "- `X`: Conjunto de características (features).\n",
    "- `y`: Vetor alvo (target).\n",
    "- `perc`: Percentual de confiança para aceitar uma característica como importante.\n",
    "- `alpha`: Nível de significância para o teste estatístico usado internamente pelo Boruta.\n",
    "- `max_iter`: Número máximo de iterações que o Boruta deve executar.\n",
    "- `max_depth`: Profundidade máxima para cada árvore no modelo RandomForest.\n",
    "- `n_estimators`: Número de árvores a serem usadas no RandomForest. Pode ser um número ou 'auto', onde o Boruta tenta determinar um número ótimo.\n",
    "- `n_jobs`: Número de trabalhos a serem executados em paralelo.\n",
    "\n",
    "### Verificação do Tipo de Dados\n",
    "O código verifica se `X` é um DataFrame do pandas e se `y` é uma Series do pandas:\n",
    "- `X_is_df`: Verdadeiro se `X` for um DataFrame.\n",
    "- `y_is_df`: Verdadeiro se `y` for uma Series.\n",
    "\n",
    "### Configuração do Selecionador Boruta\n",
    "- `selector`: Uma instância do `BorutaPy`. É configurada com um estimador (`RandomForestClassifier`), juntamente com os parâmetros fornecidos como `max_depth`, `n_jobs`, e outros parâmetros específicos do Boruta como `n_estimators`, `perc`, `alpha`, `max_iter`, `random_state`, e `verbose`.\n",
    "\n",
    "### Preparação dos Dados\n",
    "- `X_train` e `y_train` são preparados para serem compatíveis com o Boruta, convertendo-os para arrays do numpy se forem DataFrames ou Series. Isto é necessário porque o Boruta trabalha diretamente com arrays do numpy.\n",
    "\n",
    "### Execução do Boruta\n",
    "- `selector.fit(X_train, y_train)`: Este método ajusta o Boruta ao conjunto de dados fornecido, realizando a seleção de características. O Boruta usa a importância das características determinada pelo RandomForest para decidir quais características são estatisticamente significativas.\n",
    "\n",
    "### Retorno dos Resultados\n",
    "- Se `X` for um DataFrame, a função retorna uma lista das colunas consideradas importantes pelo Boruta.\n",
    "- Se `X` não for um DataFrame, a função retorna uma lista dos índices das características importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feature_boruta(X, y, \n",
    "                         perc=100,\n",
    "                         alpha=0.05,\n",
    "                         max_iter=100,\n",
    "                         max_depth=7,\n",
    "                         n_estimators='auto',\n",
    "                         n_jobs=1):\n",
    "\n",
    "    X_is_df = isinstance(X, pd.DataFrame)\n",
    "    y_is_df = isinstance(y, pd.Series)\n",
    "        \n",
    "    selector = BorutaPy(\n",
    "            estimator=RandomForestClassifier(n_estimators=100, max_depth=max_depth, n_jobs=n_jobs, class_weight='balanced_subsample'),\n",
    "            n_estimators=n_estimators,\n",
    "            perc=perc,      \n",
    "            alpha=alpha,    \n",
    "            max_iter=max_iter,\n",
    "            random_state=1,\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "    # boruta needs a numpy array, not a dataframe\n",
    "    X_train = X.values if X_is_df else X\n",
    "    y_train = y.values if y_is_df else y\n",
    "\n",
    "    selector.fit(X_train, y_train) \n",
    "        \n",
    "    if X_is_df:\n",
    "        columns = X.columns\n",
    "        return sorted(np.array(columns)[selector.support_.tolist()])\n",
    "    else:\n",
    "        return sorted(selector.support_.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChargesRatio',\n",
       " 'Contract',\n",
       " 'CustomerCluster',\n",
       " 'InternetService',\n",
       " 'MonthlyCharges',\n",
       " 'NormalizedTenure',\n",
       " 'OnlineBackup',\n",
       " 'OnlineSecurity',\n",
       " 'TechSupport',\n",
       " 'TenureGroup',\n",
       " 'TotalCharges',\n",
       " 'TotalRevenue',\n",
       " 'tenure']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = select_feature_boruta(X, y, n_jobs=10)\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo definiu que as features ['Contract',\n",
    " 'InternetService',\n",
    " 'MonthlyCharges',\n",
    " 'OnlineBackup',\n",
    " 'OnlineSecurity',\n",
    " 'TechSupport',\n",
    " 'TotalCharges',\n",
    " 'tenure'] são as mais importantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcular a Matriz de Correlação**: A função inicia calculando a matriz de correlação das variáveis no DataFrame (`df.corr()`). A função `abs()` é aplicada para considerar o valor absoluto das correlações, pois correlações fortemente negativas são tão problemáticas quanto correlações fortemente positivas em termos de multicolinearidade.\n",
    "\n",
    "**Identificar o Triângulo Superior**: A função utiliza `np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)` para criar uma máscara booleana que identifica apenas a parte superior da matriz de correlação. Isso é necessário porque a matriz de correlação é simétrica, e cada par de correlação entre variáveis é representado duas vezes (acima e abaixo da diagonal principal). A parte acima da diagonal (triângulo superior) é a única considerada para evitar duplicidade na análise de correlações altas.\n",
    "\n",
    "**Encontrar Colunas a Serem Removidas**: A lista `to_drop` é criada percorrendo todas as colunas da matriz de correlação superior e adicionando aquelas colunas cujo valor máximo de correlação com outras variáveis excede o limiar (`thresh`). Por exemplo, se o limiar é 0.95, qualquer característica que tenha uma correlação de 0.95 ou mais com outra característica será marcada para remoção.\n",
    "\n",
    "**Remover as Colunas Identificadas**: Finalmente, as colunas identificadas como altamente correlacionadas são removidas do DataFrame original (`df.drop(to_drop, axis=1)`), e o DataFrame modificado é retornado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_high_correlations(df, thresh=0.95):\n",
    "    corr_matrix = df.corr().abs()\n",
    "\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > thresh)]\n",
    "\n",
    "    return df.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChargesRatio',\n",
       " 'Contract',\n",
       " 'CustomerCluster',\n",
       " 'InternetService',\n",
       " 'MonthlyCharges',\n",
       " 'OnlineBackup',\n",
       " 'OnlineSecurity',\n",
       " 'TechSupport',\n",
       " 'TotalCharges',\n",
       " 'tenure']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_uncor = drop_high_correlations(X, thresh=0.9)\n",
    "selected_features = select_feature_boruta(X_train_uncor, y, n_jobs=20)\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_uncor, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1458 candidates, totalling 7290 fits\n",
      "Melhores hiperparâmetros encontrados: {'colsample_bynode': 0.8, 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'reg_alpha': 1, 'subsample': 1.0}\n",
      "Melhor pontuação: 0.8484097336207883\n"
     ]
    }
   ],
   "source": [
    "# Definindo o grid de hiperparâmetros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150], # Número de árvores a serem construídas. Aumentar pode melhorar a performance, mas também aumenta o tempo de treinamento e o risco de overfitting.\n",
    "    'learning_rate': [0.01, 0.05, 0.1],# Taxa de aprendizado, controla o impacto de cada árvore. Aumentar pode acelerar o treinamento, mas pode causar overfitting.\n",
    "    'max_depth': [2, 4, 6], # Profundidade máxima das árvores. Aumentar pode melhorar a capacidade do modelo, mas aumenta o risco de overfitting.\n",
    "    'subsample': [0.7, 0.8, 1.0], # Porcentagem de amostras usadas para treinar cada árvore. Aumentar pode ajudar a reduzir overfitting.\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0], # Porcentagem de características usadas para treinar cada árvore. Aumentar pode melhorar a performance, mas também o risco de overfitting.\n",
    "    'reg_alpha': [0.01, 0.1, 1], # Termo de regularização L1. Aumentar pode tornar o modelo mais esparso e reduzir overfitting.\n",
    "    'colsample_bynode': [0.7, 0.8, 1.0],  # Porcentagem de características usadas por nó. Aumentar pode melhorar a performance, mas aumenta o risco de overfitting.\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0], # Porcentagem de características usadas para treinar cada árvore. Aumentar pode melhorar a performance, mas também o risco de overfitting.\n",
    "    #'scale_pos_weight': [1, 2, 5], # Balanceamento entre classes positivas e negativas. Aumentar pode ajudar em datasets desbalanceados.\n",
    "}\n",
    "\n",
    "# Configurando o modelo XGBoost\n",
    "xg_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Definindo a validação cruzada estratificada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Configurando o GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xg_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',  # roc_auc é uma métrica ponderada\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "# Executando o GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtendo os melhores hiperparâmetros\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Melhores hiperparâmetros encontrados:\", best_params)\n",
    "print(\"Melhor pontuação:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8166614073840328\n"
     ]
    }
   ],
   "source": [
    "# Acurácia em X_train\n",
    "predictions = grid_search.predict(X_train)\n",
    "print(\"Accuracy:\", accuracy_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8099290780141843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.88       511\n",
      "           1       0.71      0.52      0.60       194\n",
      "\n",
      "    accuracy                           0.81       705\n",
      "   macro avg       0.77      0.72      0.74       705\n",
      "weighted avg       0.80      0.81      0.80       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = grid_search.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML - lazypredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `LazyPredict` é uma biblioteca Python que automatiza a construção, o treinamento e a avaliação de diversos modelos de machine learning de maneira rápida e fácil. O objetivo principal é permitir que os usuários comparem rapidamente o desempenho de diferentes modelos sem precisar escrever muito código para cada modelo individualmente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:17<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1675, number of negative: 4663\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 904\n",
      "[LightGBM] [Info] Number of data points in the train set: 6338, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.264279 -> initscore=-1.023846\n",
      "[LightGBM] [Info] Start training from score -1.023846\n",
      "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "BernoulliNB                        0.78               0.77     0.77      0.79   \n",
      "GaussianNB                         0.77               0.77     0.77      0.78   \n",
      "NearestCentroid                    0.74               0.76     0.76      0.75   \n",
      "LinearDiscriminantAnalysis         0.82               0.75     0.75      0.82   \n",
      "LinearSVC                          0.82               0.73     0.73      0.81   \n",
      "CalibratedClassifierCV             0.82               0.73     0.73      0.81   \n",
      "LogisticRegression                 0.81               0.73     0.73      0.81   \n",
      "RidgeClassifierCV                  0.82               0.73     0.73      0.81   \n",
      "RidgeClassifier                    0.82               0.73     0.73      0.81   \n",
      "LGBMClassifier                     0.81               0.72     0.72      0.80   \n",
      "PassiveAggressiveClassifier        0.75               0.72     0.72      0.76   \n",
      "AdaBoostClassifier                 0.80               0.71     0.71      0.79   \n",
      "XGBClassifier                      0.79               0.71     0.71      0.79   \n",
      "RandomForestClassifier             0.80               0.70     0.70      0.79   \n",
      "SVC                                0.80               0.70     0.70      0.79   \n",
      "Perceptron                         0.74               0.68     0.68      0.74   \n",
      "BaggingClassifier                  0.78               0.68     0.68      0.77   \n",
      "ExtraTreesClassifier               0.78               0.68     0.68      0.77   \n",
      "LabelSpreading                     0.74               0.67     0.67      0.74   \n",
      "KNeighborsClassifier               0.76               0.67     0.67      0.75   \n",
      "LabelPropagation                   0.74               0.67     0.67      0.74   \n",
      "SGDClassifier                      0.77               0.66     0.66      0.76   \n",
      "NuSVC                              0.79               0.65     0.65      0.76   \n",
      "DecisionTreeClassifier             0.71               0.64     0.64      0.71   \n",
      "ExtraTreeClassifier                0.73               0.64     0.64      0.73   \n",
      "QuadraticDiscriminantAnalysis      0.42               0.52     0.52      0.43   \n",
      "DummyClassifier                    0.72               0.50     0.50      0.61   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "BernoulliNB                          0.03  \n",
      "GaussianNB                           0.02  \n",
      "NearestCentroid                      0.03  \n",
      "LinearDiscriminantAnalysis           0.06  \n",
      "LinearSVC                            0.61  \n",
      "CalibratedClassifierCV               1.78  \n",
      "LogisticRegression                   0.05  \n",
      "RidgeClassifierCV                    0.04  \n",
      "RidgeClassifier                      0.03  \n",
      "LGBMClassifier                       0.36  \n",
      "PassiveAggressiveClassifier          0.04  \n",
      "AdaBoostClassifier                   0.41  \n",
      "XGBClassifier                        0.20  \n",
      "RandomForestClassifier               0.81  \n",
      "SVC                                  1.76  \n",
      "Perceptron                           0.04  \n",
      "BaggingClassifier                    0.28  \n",
      "ExtraTreesClassifier                 1.02  \n",
      "LabelSpreading                       3.96  \n",
      "KNeighborsClassifier                 0.07  \n",
      "LabelPropagation                     3.13  \n",
      "SGDClassifier                        0.05  \n",
      "NuSVC                                2.31  \n",
      "DecisionTreeClassifier               0.05  \n",
      "ExtraTreeClassifier                  0.03  \n",
      "QuadraticDiscriminantAnalysis        0.04  \n",
      "DummyClassifier                      0.02  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GaussianNB(), n_jobs=2,\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.70359136e-01, 7.57525026e-01, 6.59318827e-01,\n",
       "       5.73844165e-01, 4.99450512e-01, 4.34701316e-01, 3.78346262e-01,\n",
       "       3.29297126e-01, 2.86606762e-01, 2.49450814e-01, 2.17111795e-01,\n",
       "       1.88965234e-01, 1.64467618e-01, 1.43145894e-01, 1.24588336e-01,\n",
       "       1.08436597e-01, 9.43787828...\n",
       "       2.43744415e-11, 2.12145178e-11, 1.84642494e-11, 1.60705282e-11,\n",
       "       1.39871310e-11, 1.21738273e-11, 1.05956018e-11, 9.22197882e-12,\n",
       "       8.02643352e-12, 6.98587975e-12, 6.08022426e-12, 5.29197874e-12,\n",
       "       4.60592204e-12, 4.00880633e-12, 3.48910121e-12, 3.03677112e-12,\n",
       "       2.64308149e-12, 2.30043012e-12, 2.00220037e-12, 1.74263339e-12,\n",
       "       1.51671689e-12, 1.32008840e-12, 1.14895100e-12, 1.00000000e-12])},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GaussianNB(), n_jobs=2,\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.70359136e-01, 7.57525026e-01, 6.59318827e-01,\n",
       "       5.73844165e-01, 4.99450512e-01, 4.34701316e-01, 3.78346262e-01,\n",
       "       3.29297126e-01, 2.86606762e-01, 2.49450814e-01, 2.17111795e-01,\n",
       "       1.88965234e-01, 1.64467618e-01, 1.43145894e-01, 1.24588336e-01,\n",
       "       1.08436597e-01, 9.43787828...\n",
       "       2.43744415e-11, 2.12145178e-11, 1.84642494e-11, 1.60705282e-11,\n",
       "       1.39871310e-11, 1.21738273e-11, 1.05956018e-11, 9.22197882e-12,\n",
       "       8.02643352e-12, 6.98587975e-12, 6.08022426e-12, 5.29197874e-12,\n",
       "       4.60592204e-12, 4.00880633e-12, 3.48910121e-12, 3.03677112e-12,\n",
       "       2.64308149e-12, 2.30043012e-12, 2.00220037e-12, 1.74263339e-12,\n",
       "       1.51671689e-12, 1.32008840e-12, 1.14895100e-12, 1.00000000e-12])},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GaussianNB(), n_jobs=2,\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.70359136e-01, 7.57525026e-01, 6.59318827e-01,\n",
       "       5.73844165e-01, 4.99450512e-01, 4.34701316e-01, 3.78346262e-01,\n",
       "       3.29297126e-01, 2.86606762e-01, 2.49450814e-01, 2.17111795e-01,\n",
       "       1.88965234e-01, 1.64467618e-01, 1.43145894e-01, 1.24588336e-01,\n",
       "       1.08436597e-01, 9.43787828...\n",
       "       2.43744415e-11, 2.12145178e-11, 1.84642494e-11, 1.60705282e-11,\n",
       "       1.39871310e-11, 1.21738273e-11, 1.05956018e-11, 9.22197882e-12,\n",
       "       8.02643352e-12, 6.98587975e-12, 6.08022426e-12, 5.29197874e-12,\n",
       "       4.60592204e-12, 4.00880633e-12, 3.48910121e-12, 3.03677112e-12,\n",
       "       2.64308149e-12, 2.30043012e-12, 2.00220037e-12, 1.74263339e-12,\n",
       "       1.51671689e-12, 1.32008840e-12, 1.14895100e-12, 1.00000000e-12])},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo o modelo GaussianNB\n",
    "model = GaussianNB()\n",
    "\n",
    "# Definindo os hiperparâmetros para a busca\n",
    "param_grid = {\n",
    "    'var_smoothing': np.logspace(0, -12, num=200),\n",
    "    \n",
    "}\n",
    "\n",
    "# Configurando o GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=2)\n",
    "\n",
    "# Treinando o modelo com GridSearchCV\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7860523824550332\n"
     ]
    }
   ],
   "source": [
    "# Acurácia em X_train\n",
    "predictions = grid_search.predict(X_train)\n",
    "print(\"Accuracy:\", accuracy_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'var_smoothing': 0.00012033778407775906}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       511\n",
      "           1       0.77      0.37      0.50       194\n",
      "\n",
      "    accuracy                           0.80       705\n",
      "   macro avg       0.78      0.66      0.69       705\n",
      "weighted avg       0.79      0.80      0.77       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtendo os melhores hiperparâmetros\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Melhores hiperparâmetros:\", best_params)\n",
    "\n",
    "# Treinando o modelo final com os melhores hiperparâmetros\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Fazendo previsões e avaliando o modelo\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearDiscriminantAnalysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=LinearDiscriminantAnalysis(), n_jobs=-1,\n",
       "             param_grid={&#x27;n_components&#x27;: [None, 1, 2, 3],\n",
       "                         &#x27;shrinkage&#x27;: [None, &#x27;auto&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;svd&#x27;, &#x27;lsqr&#x27;, &#x27;eigen&#x27;],\n",
       "                         &#x27;store_covariance&#x27;: [True, False],\n",
       "                         &#x27;tol&#x27;: [0.0001, 1e-05, 1e-06]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=LinearDiscriminantAnalysis(), n_jobs=-1,\n",
       "             param_grid={&#x27;n_components&#x27;: [None, 1, 2, 3],\n",
       "                         &#x27;shrinkage&#x27;: [None, &#x27;auto&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;svd&#x27;, &#x27;lsqr&#x27;, &#x27;eigen&#x27;],\n",
       "                         &#x27;store_covariance&#x27;: [True, False],\n",
       "                         &#x27;tol&#x27;: [0.0001, 1e-05, 1e-06]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LinearDiscriminantAnalysis(), n_jobs=-1,\n",
       "             param_grid={'n_components': [None, 1, 2, 3],\n",
       "                         'shrinkage': [None, 'auto'],\n",
       "                         'solver': ['svd', 'lsqr', 'eigen'],\n",
       "                         'store_covariance': [True, False],\n",
       "                         'tol': [0.0001, 1e-05, 1e-06]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo o modelo LinearDiscriminantAnalysis\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Definindo os hiperparâmetros para a busca\n",
    "param_grid = {\n",
    "    'solver': ['svd', 'lsqr', 'eigen'],           # Métodos de solução para LDA\n",
    "    'shrinkage': [None, 'auto'],                  # Tipo de encolhimento\n",
    "    'n_components': [None, 1, 2, 3],               # Número de componentes a serem mantidos\n",
    "    'tol': [1e-4, 1e-5, 1e-6],                     # Tolerância para convergência\n",
    "    'store_covariance': [True, False],             # Armazenar ou não a covariância\n",
    "}\n",
    "# Configurando o GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Treinando o modelo com GridSearchCV\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'n_components': None, 'shrinkage': 'auto', 'solver': 'lsqr', 'store_covariance': True, 'tol': 0.0001}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88       511\n",
      "           1       0.72      0.57      0.64       194\n",
      "\n",
      "    accuracy                           0.82       705\n",
      "   macro avg       0.79      0.74      0.76       705\n",
      "weighted avg       0.81      0.82      0.81       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtendo os melhores hiperparâmetros\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Melhores hiperparâmetros:\", best_params)\n",
    "\n",
    "# Treinando o modelo final com os melhores hiperparâmetros\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Fazendo previsões e avaliando o modelo\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=CalibratedClassifierCV(base_estimator=LinearSVC(random_state=42)),\n",
       "             n_jobs=2,\n",
       "             param_grid={&#x27;base_estimator__C&#x27;: [0.001, 0.01, 0.1, 1.0, 10.0],\n",
       "                         &#x27;base_estimator__loss&#x27;: [&#x27;hinge&#x27;, &#x27;squared_hinge&#x27;],\n",
       "                         &#x27;base_estimator__max_iter&#x27;: [2000, 3000, 4000],\n",
       "                         &#x27;base_estimator__tol&#x27;: [0.001, 0.0001, 1e-05],\n",
       "                         &#x27;method&#x27;: [&#x27;sigmoid&#x27;]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=CalibratedClassifierCV(base_estimator=LinearSVC(random_state=42)),\n",
       "             n_jobs=2,\n",
       "             param_grid={&#x27;base_estimator__C&#x27;: [0.001, 0.01, 0.1, 1.0, 10.0],\n",
       "                         &#x27;base_estimator__loss&#x27;: [&#x27;hinge&#x27;, &#x27;squared_hinge&#x27;],\n",
       "                         &#x27;base_estimator__max_iter&#x27;: [2000, 3000, 4000],\n",
       "                         &#x27;base_estimator__tol&#x27;: [0.001, 0.0001, 1e-05],\n",
       "                         &#x27;method&#x27;: [&#x27;sigmoid&#x27;]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: CalibratedClassifierCV</label><div class=\"sk-toggleable__content\"><pre>CalibratedClassifierCV(base_estimator=LinearSVC(random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=CalibratedClassifierCV(base_estimator=LinearSVC(random_state=42)),\n",
       "             n_jobs=2,\n",
       "             param_grid={'base_estimator__C': [0.001, 0.01, 0.1, 1.0, 10.0],\n",
       "                         'base_estimator__loss': ['hinge', 'squared_hinge'],\n",
       "                         'base_estimator__max_iter': [2000, 3000, 4000],\n",
       "                         'base_estimator__tol': [0.001, 0.0001, 1e-05],\n",
       "                         'method': ['sigmoid']},\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo o modelo base e seus hiperparâmetros\n",
    "base_model = LinearSVC(random_state=42)\n",
    "\n",
    "# Definindo o CalibratedClassifierCV e seus hiperparâmetros\n",
    "calibrated_model = CalibratedClassifierCV(base_estimator=base_model)\n",
    "\n",
    "# Definindo os hiperparâmetros para a busca\n",
    "param_grid = {\n",
    "    'base_estimator__C': [0.001, 0.01, 0.1, 1.0, 10.0],  \n",
    "    'base_estimator__loss': ['hinge', 'squared_hinge'],  \n",
    "    'base_estimator__max_iter': [2000, 3000, 4000],      \n",
    "    'base_estimator__tol': [1e-3, 1e-4, 1e-5],           \n",
    "    'method': ['sigmoid']                   \n",
    "}\n",
    "\n",
    "# Configurando o GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=calibrated_model, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=1, n_jobs=2)\n",
    "\n",
    "# Treinando o modelo com GridSearchCV\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'base_estimator__C': 0.001, 'base_estimator__loss': 'squared_hinge', 'base_estimator__max_iter': 4000, 'base_estimator__tol': 0.001, 'method': 'sigmoid'}\n",
      "Acurácia do modelo com melhores hiperparâmetros: 0.8056737588652483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       511\n",
      "           1       0.70      0.51      0.59       194\n",
      "\n",
      "    accuracy                           0.81       705\n",
      "   macro avg       0.77      0.71      0.73       705\n",
      "weighted avg       0.80      0.81      0.80       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtendo os melhores hiperparâmetros\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Melhores hiperparâmetros:\", best_params)\n",
    "\n",
    "# Treinando o modelo final com os melhores hiperparâmetros\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Fazendo previsões e avaliando o modelo\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Acurácia do modelo com melhores hiperparâmetros:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novo ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Train_accuracy: 0.8231303250236668\n",
      "Ensemble Test_accuracy: 0.8226950354609929\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       511\n",
      "           1       0.69      0.64      0.67       194\n",
      "\n",
      "    accuracy                           0.82       705\n",
      "   macro avg       0.78      0.77      0.77       705\n",
      "weighted avg       0.82      0.82      0.82       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modelos\n",
    "model_dict = {\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'XGBClassifier': xgb.XGBClassifier(objective='binary:logistic', random_state=42),\n",
    "    'LinearDiscriminantAnalysis': LinearDiscriminantAnalysis(),\n",
    "    'CalibratedClassifierCV': CalibratedClassifierCV(base_estimator=LinearSVC(random_state=42)),\n",
    "}\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Definindo pesos para cada classificador\n",
    "weights = [0.89, 1.135, 2.5, 0.57]  # Exemplo de pesos; ajuste conforme necessário\n",
    "\n",
    "# Criando o ensemble usando VotingClassifier com pesos\n",
    "ensemble_model = VotingClassifier(estimators=list(model_dict.items()), voting='soft', weights=weights) \n",
    "\n",
    "# Treinando o ensemble\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Avaliando o ensemble\n",
    "accuracy = ensemble_model.score(X_train, y_train)\n",
    "print(\"Ensemble Train_accuracy:\", accuracy)\n",
    "accuracy = ensemble_model.score(X_test, y_test)\n",
    "print(\"Ensemble Test_accuracy:\", accuracy)\n",
    "\n",
    "# Classification report\n",
    "predictions = ensemble_model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretação das Métricas\n",
    "\n",
    "- **Precisão (Precision)**: A precisão para a classe 0 é alta (0.87), indicando que a maioria das previsões de \"não churn\" estão corretas. Para a classe 1, a precisão é mais baixa (0.69), sugerindo que há um número maior de falsos positivos na previsão de churn.\n",
    "\n",
    "- **Recall**: O recall para a classe 0 também é alto (0.89), significando que a maioria dos clientes que realmente não churnaram foram corretamente identificados. Para a classe 1, o recall é mais baixo (0.64), indicando que o modelo está perdendo alguns clientes que realmente churnaram (falsos negativos).\n",
    "\n",
    "- **F1-Score**: O F1-score combina precisão e recall. Para a classe 0, o F1-score é 0.88, refletindo um bom equilíbrio entre precisão e recall. Para a classe 1, o F1-score é 0.67, mostrando uma menor eficácia na previsão de churn comparado com a classe 0.\n",
    "\n",
    "- **Acurácia (Accuracy)**: A acurácia geral do modelo é 0.82, o que é um bom indicativo de que o modelo está fazendo previsões corretas na maioria dos casos.\n",
    "\n",
    "- **Macro média (Macro avg)** e **Média ponderada (Weighted avg)**: Essas métricas oferecem uma visão geral do desempenho do modelo, com a média ponderada refletindo a distribuição das classes. Ambas as médias indicam um bom desempenho geral, mas a média ponderada, sendo igual à acurácia (0.82), destaca a importância da classe maioritária.\n",
    "\n",
    "Esses resultados mostram que o modelo tem um bom desempenho geral, especialmente para identificar clientes que não churnam. No entanto, há espaço para melhorar a identificação de clientes que churnam, com a coleta de mais dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
