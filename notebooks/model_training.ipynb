{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.23.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento dos dados\n",
    "dataset = pd.read_csv('../data/WA_Fn-UseC_-Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID          0\n",
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "MultipleLines       0\n",
       "InternetService     0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "PaperlessBilling    0\n",
       "PaymentMethod       0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verificar nan em dataset\n",
    "display(dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter TotalCharges para float\n",
    "dataset['TotalCharges'] = pd.to_numeric(dataset['TotalCharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID           0\n",
       "gender               0\n",
       "SeniorCitizen        0\n",
       "Partner              0\n",
       "Dependents           0\n",
       "tenure               0\n",
       "PhoneService         0\n",
       "MultipleLines        0\n",
       "InternetService      0\n",
       "OnlineSecurity       0\n",
       "OnlineBackup         0\n",
       "DeviceProtection     0\n",
       "TechSupport          0\n",
       "StreamingTV          0\n",
       "StreamingMovies      0\n",
       "Contract             0\n",
       "PaperlessBilling     0\n",
       "PaymentMethod        0\n",
       "MonthlyCharges       0\n",
       "TotalCharges        11\n",
       "Churn                0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verificar nan em dataset\n",
    "display(dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover a coluna 'customerID'\n",
    "dataset.drop('customerID', axis=1, inplace=True)\n",
    "\n",
    "# Selecionar colunas categóricas, mantendo as colunas do tipo int e float no DataFrame\n",
    "categorical_cols = dataset.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Criar dummies para as colunas categóricas\n",
    "dataset_dummies = pd.get_dummies(dataset, columns=categorical_cols, drop_first=False)\n",
    "\n",
    "# Separar as features e o target\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(dataset_dummies.drop('TotalCharges', axis=1))  # remove 'TotalCharges' from the features\n",
    "\n",
    "# Após a normalização, a coluna 'TotalCharges' é adicionada de volta ao array de features\n",
    "features_scaled = np.column_stack((features_scaled, dataset_dummies['TotalCharges']))\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=10) # Usa o KNN para preencher os valores faltantes\n",
    "features_imputed = imputer.fit_transform(features_scaled)\n",
    "\n",
    "# Adicionar 'TotalCharges' como última coluna\n",
    "dataset['TotalCharges'] = features_imputed[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar colunas categóricas, mantendo as colunas do tipo int e float no DataFrame\n",
    "categorical_cols = dataset.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Criar dummies para as colunas categóricas\n",
    "dataset_dummies = pd.get_dummies(dataset, columns=categorical_cols, drop_first=False)\n",
    "\n",
    "# Dividindo os dados em características e target\n",
    "X = dataset_dummies.drop(['Churn_Yes', 'Churn_No'], axis=1)  # Características\n",
    "y = dataset_dummies['Churn_Yes']  # Churn_Yes ja tem 0 e 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do modelo XGBoost\n",
    "xg_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    subsample=0.5,\n",
    "    colsample_bytree=0.5,\n",
    "    objective='binary:logistic',\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.5, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8113475177304964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.91      0.88       511\n",
      "        True       0.70      0.54      0.61       194\n",
      "\n",
      "    accuracy                           0.81       705\n",
      "   macro avg       0.77      0.73      0.74       705\n",
      "weighted avg       0.80      0.81      0.80       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = xg_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               5888      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,257\n",
      "Trainable params: 16,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "nn_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.01)), \n",
    "    Dropout(0.3), \n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.3), \n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.3), \n",
    "    Dense(1, activation='sigmoid') \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "nn_model.compile(optimizer='adam',\n",
    "              loss= BinaryCrossentropy(from_logits=False), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "179/179 [==============================] - 2s 5ms/step - loss: 25.7494 - accuracy: 0.6413 - val_loss: 6.0420 - val_accuracy: 0.7823\n",
      "Epoch 2/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 6.7227 - accuracy: 0.6534 - val_loss: 1.7292 - val_accuracy: 0.7808\n",
      "Epoch 3/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 3.1121 - accuracy: 0.6630 - val_loss: 1.4061 - val_accuracy: 0.7618\n",
      "Epoch 4/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 1.6795 - accuracy: 0.7049 - val_loss: 1.3620 - val_accuracy: 0.7618\n",
      "Epoch 5/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.4902 - accuracy: 0.7309 - val_loss: 1.3467 - val_accuracy: 0.7618\n",
      "Epoch 6/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.3839 - accuracy: 0.7397 - val_loss: 1.3151 - val_accuracy: 0.7618\n",
      "Epoch 7/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.3596 - accuracy: 0.7390 - val_loss: 1.2891 - val_accuracy: 0.7634\n",
      "Epoch 8/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.3133 - accuracy: 0.7475 - val_loss: 1.2561 - val_accuracy: 0.7792\n",
      "Epoch 9/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.2928 - accuracy: 0.7468 - val_loss: 1.2442 - val_accuracy: 0.7808\n",
      "Epoch 10/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.2726 - accuracy: 0.7484 - val_loss: 1.2227 - val_accuracy: 0.7760\n",
      "Epoch 11/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.2481 - accuracy: 0.7556 - val_loss: 1.1986 - val_accuracy: 0.7839\n",
      "Epoch 12/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.2342 - accuracy: 0.7488 - val_loss: 1.1807 - val_accuracy: 0.7808\n",
      "Epoch 13/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.2063 - accuracy: 0.7523 - val_loss: 1.1556 - val_accuracy: 0.7792\n",
      "Epoch 14/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 1.1890 - accuracy: 0.7540 - val_loss: 1.1371 - val_accuracy: 0.7808\n",
      "Epoch 15/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.1568 - accuracy: 0.7530 - val_loss: 1.1197 - val_accuracy: 0.7839\n",
      "Epoch 16/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.1413 - accuracy: 0.7567 - val_loss: 1.1005 - val_accuracy: 0.7855\n",
      "Epoch 17/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.1296 - accuracy: 0.7544 - val_loss: 1.0737 - val_accuracy: 0.7744\n",
      "Epoch 18/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.0964 - accuracy: 0.7535 - val_loss: 1.0590 - val_accuracy: 0.7855\n",
      "Epoch 19/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.0757 - accuracy: 0.7596 - val_loss: 1.0320 - val_accuracy: 0.7823\n",
      "Epoch 20/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.0550 - accuracy: 0.7533 - val_loss: 1.0115 - val_accuracy: 0.7839\n",
      "Epoch 21/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 1.0363 - accuracy: 0.7570 - val_loss: 0.9929 - val_accuracy: 0.7808\n",
      "Epoch 22/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 1.0135 - accuracy: 0.7577 - val_loss: 0.9749 - val_accuracy: 0.7823\n",
      "Epoch 23/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.9990 - accuracy: 0.7500 - val_loss: 0.9513 - val_accuracy: 0.7855\n",
      "Epoch 24/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.9762 - accuracy: 0.7582 - val_loss: 0.9347 - val_accuracy: 0.7855\n",
      "Epoch 25/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.9714 - accuracy: 0.7570 - val_loss: 0.9135 - val_accuracy: 0.7823\n",
      "Epoch 26/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.9305 - accuracy: 0.7584 - val_loss: 0.8930 - val_accuracy: 0.7839\n",
      "Epoch 27/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.9189 - accuracy: 0.7530 - val_loss: 0.8798 - val_accuracy: 0.7886\n",
      "Epoch 28/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.8954 - accuracy: 0.7570 - val_loss: 0.8574 - val_accuracy: 0.7839\n",
      "Epoch 29/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.8826 - accuracy: 0.7575 - val_loss: 0.8413 - val_accuracy: 0.7776\n",
      "Epoch 30/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.8582 - accuracy: 0.7593 - val_loss: 0.8159 - val_accuracy: 0.7871\n",
      "Epoch 31/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.8391 - accuracy: 0.7621 - val_loss: 0.7936 - val_accuracy: 0.7871\n",
      "Epoch 32/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.8317 - accuracy: 0.7572 - val_loss: 0.7831 - val_accuracy: 0.7823\n",
      "Epoch 33/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.8030 - accuracy: 0.7605 - val_loss: 0.7626 - val_accuracy: 0.7823\n",
      "Epoch 34/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.7910 - accuracy: 0.7591 - val_loss: 0.7461 - val_accuracy: 0.7871\n",
      "Epoch 35/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.7682 - accuracy: 0.7568 - val_loss: 0.7275 - val_accuracy: 0.7855\n",
      "Epoch 36/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.7465 - accuracy: 0.7617 - val_loss: 0.7062 - val_accuracy: 0.7839\n",
      "Epoch 37/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.7335 - accuracy: 0.7595 - val_loss: 0.6976 - val_accuracy: 0.7839\n",
      "Epoch 38/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.7181 - accuracy: 0.7586 - val_loss: 0.6768 - val_accuracy: 0.7871\n",
      "Epoch 39/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6966 - accuracy: 0.7646 - val_loss: 0.6677 - val_accuracy: 0.7808\n",
      "Epoch 40/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6864 - accuracy: 0.7616 - val_loss: 0.6424 - val_accuracy: 0.7839\n",
      "Epoch 41/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6682 - accuracy: 0.7600 - val_loss: 0.6327 - val_accuracy: 0.7839\n",
      "Epoch 42/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6522 - accuracy: 0.7637 - val_loss: 0.6136 - val_accuracy: 0.7855\n",
      "Epoch 43/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6384 - accuracy: 0.7610 - val_loss: 0.5999 - val_accuracy: 0.7839\n",
      "Epoch 44/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6271 - accuracy: 0.7633 - val_loss: 0.5941 - val_accuracy: 0.7855\n",
      "Epoch 45/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.6171 - accuracy: 0.7654 - val_loss: 0.5863 - val_accuracy: 0.7823\n",
      "Epoch 46/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.6047 - accuracy: 0.7612 - val_loss: 0.5653 - val_accuracy: 0.7823\n",
      "Epoch 47/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5950 - accuracy: 0.7633 - val_loss: 0.5569 - val_accuracy: 0.7886\n",
      "Epoch 48/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5853 - accuracy: 0.7667 - val_loss: 0.5374 - val_accuracy: 0.7981\n",
      "Epoch 49/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5758 - accuracy: 0.7688 - val_loss: 0.5332 - val_accuracy: 0.7902\n",
      "Epoch 50/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5657 - accuracy: 0.7672 - val_loss: 0.5374 - val_accuracy: 0.7871\n",
      "Epoch 51/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5603 - accuracy: 0.7670 - val_loss: 0.5187 - val_accuracy: 0.7871\n",
      "Epoch 52/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5586 - accuracy: 0.7617 - val_loss: 0.5151 - val_accuracy: 0.7950\n",
      "Epoch 53/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5433 - accuracy: 0.7721 - val_loss: 0.5044 - val_accuracy: 0.7871\n",
      "Epoch 54/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5351 - accuracy: 0.7719 - val_loss: 0.4989 - val_accuracy: 0.7871\n",
      "Epoch 55/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5327 - accuracy: 0.7747 - val_loss: 0.5022 - val_accuracy: 0.7855\n",
      "Epoch 56/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5252 - accuracy: 0.7709 - val_loss: 0.4918 - val_accuracy: 0.7886\n",
      "Epoch 57/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5235 - accuracy: 0.7730 - val_loss: 0.4880 - val_accuracy: 0.7855\n",
      "Epoch 58/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5238 - accuracy: 0.7668 - val_loss: 0.4841 - val_accuracy: 0.7950\n",
      "Epoch 59/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5140 - accuracy: 0.7707 - val_loss: 0.4811 - val_accuracy: 0.7902\n",
      "Epoch 60/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5139 - accuracy: 0.7698 - val_loss: 0.4782 - val_accuracy: 0.7918\n",
      "Epoch 61/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5133 - accuracy: 0.7751 - val_loss: 0.4797 - val_accuracy: 0.7886\n",
      "Epoch 62/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5080 - accuracy: 0.7716 - val_loss: 0.4761 - val_accuracy: 0.7886\n",
      "Epoch 63/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5105 - accuracy: 0.7693 - val_loss: 0.4747 - val_accuracy: 0.7934\n",
      "Epoch 64/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5078 - accuracy: 0.7703 - val_loss: 0.4638 - val_accuracy: 0.7855\n",
      "Epoch 65/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5074 - accuracy: 0.7714 - val_loss: 0.4609 - val_accuracy: 0.7855\n",
      "Epoch 66/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5097 - accuracy: 0.7689 - val_loss: 0.4683 - val_accuracy: 0.7950\n",
      "Epoch 67/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5040 - accuracy: 0.7651 - val_loss: 0.4670 - val_accuracy: 0.7918\n",
      "Epoch 68/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5089 - accuracy: 0.7684 - val_loss: 0.4732 - val_accuracy: 0.7855\n",
      "Epoch 69/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5001 - accuracy: 0.7712 - val_loss: 0.4663 - val_accuracy: 0.7823\n",
      "Epoch 70/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5046 - accuracy: 0.7705 - val_loss: 0.4613 - val_accuracy: 0.7871\n",
      "Epoch 71/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5007 - accuracy: 0.7737 - val_loss: 0.4644 - val_accuracy: 0.7871\n",
      "Epoch 72/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4963 - accuracy: 0.7738 - val_loss: 0.4586 - val_accuracy: 0.7950\n",
      "Epoch 73/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4986 - accuracy: 0.7702 - val_loss: 0.4635 - val_accuracy: 0.7886\n",
      "Epoch 74/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.4992 - accuracy: 0.7742 - val_loss: 0.4541 - val_accuracy: 0.7918\n",
      "Epoch 75/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5074 - accuracy: 0.7672 - val_loss: 0.4615 - val_accuracy: 0.7886\n",
      "Epoch 76/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4956 - accuracy: 0.7719 - val_loss: 0.4575 - val_accuracy: 0.7855\n",
      "Epoch 77/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4980 - accuracy: 0.7712 - val_loss: 0.4585 - val_accuracy: 0.7886\n",
      "Epoch 78/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5015 - accuracy: 0.7679 - val_loss: 0.4565 - val_accuracy: 0.7918\n",
      "Epoch 79/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4971 - accuracy: 0.7749 - val_loss: 0.4562 - val_accuracy: 0.7871\n",
      "Epoch 80/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4967 - accuracy: 0.7702 - val_loss: 0.4564 - val_accuracy: 0.7839\n",
      "Epoch 81/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.4948 - accuracy: 0.7728 - val_loss: 0.4667 - val_accuracy: 0.7950\n",
      "Epoch 82/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4956 - accuracy: 0.7751 - val_loss: 0.4521 - val_accuracy: 0.7855\n",
      "Epoch 83/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4954 - accuracy: 0.7756 - val_loss: 0.4557 - val_accuracy: 0.7886\n",
      "Epoch 84/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4966 - accuracy: 0.7738 - val_loss: 0.4558 - val_accuracy: 0.7871\n",
      "Epoch 85/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4958 - accuracy: 0.7712 - val_loss: 0.4669 - val_accuracy: 0.7886\n",
      "Epoch 86/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4936 - accuracy: 0.7751 - val_loss: 0.4544 - val_accuracy: 0.7902\n",
      "Epoch 87/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5022 - accuracy: 0.7667 - val_loss: 0.4586 - val_accuracy: 0.7950\n",
      "Epoch 88/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4906 - accuracy: 0.7705 - val_loss: 0.4545 - val_accuracy: 0.7823\n",
      "Epoch 89/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.5008 - accuracy: 0.7733 - val_loss: 0.4656 - val_accuracy: 0.7886\n",
      "Epoch 90/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4953 - accuracy: 0.7742 - val_loss: 0.4555 - val_accuracy: 0.7871\n",
      "Epoch 91/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.5002 - accuracy: 0.7691 - val_loss: 0.4546 - val_accuracy: 0.7902\n",
      "Epoch 92/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4935 - accuracy: 0.7714 - val_loss: 0.4610 - val_accuracy: 0.7950\n",
      "Epoch 93/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4964 - accuracy: 0.7735 - val_loss: 0.4643 - val_accuracy: 0.7902\n",
      "Epoch 94/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4984 - accuracy: 0.7703 - val_loss: 0.4642 - val_accuracy: 0.7950\n",
      "Epoch 95/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4960 - accuracy: 0.7717 - val_loss: 0.4555 - val_accuracy: 0.7823\n",
      "Epoch 96/100\n",
      "179/179 [==============================] - 1s 4ms/step - loss: 0.4928 - accuracy: 0.7730 - val_loss: 0.4564 - val_accuracy: 0.7823\n",
      "Epoch 97/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4963 - accuracy: 0.7674 - val_loss: 0.4638 - val_accuracy: 0.7950\n",
      "Epoch 98/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4965 - accuracy: 0.7721 - val_loss: 0.4618 - val_accuracy: 0.7886\n",
      "Epoch 99/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4996 - accuracy: 0.7742 - val_loss: 0.4573 - val_accuracy: 0.7886\n",
      "Epoch 100/100\n",
      "179/179 [==============================] - 1s 3ms/step - loss: 0.4920 - accuracy: 0.7738 - val_loss: 0.4622 - val_accuracy: 0.7871\n"
     ]
    }
   ],
   "source": [
    "history = nn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotar a curva de perda de um modo\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7787\n",
      "Test Accuracy: 0.778723418712616\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "test_loss, test_acc = nn_model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.95      0.86       511\n",
      "         1.0       0.71      0.34      0.45       194\n",
      "\n",
      "    accuracy                           0.78       705\n",
      "   macro avg       0.75      0.64      0.66       705\n",
      "weighted avg       0.77      0.78      0.75       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "predictions = nn_model.predict(X_test)\n",
    "predictions = (predictions > 0.5).astype(int)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "nn_predictions = nn_model.predict(X_test)[:, 0]  # Retorna a probabilidade da classe positiva\n",
    "xgb_predictions = xg_model.predict_proba(X_test)[:, 1]  # Retorna a probabilidade da classe positiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Média das previsões\n",
    "final_predictions = (nn_predictions + xgb_predictions) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.8042553191489362\n"
     ]
    }
   ],
   "source": [
    "# Acurácia\n",
    "final_class_predictions = (final_predictions > 0.5).astype(int)\n",
    "print(\"Ensemble Accuracy:\", accuracy_score(y_test, final_class_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.94      0.87       511\n",
      "         1.0       0.75      0.44      0.55       194\n",
      "\n",
      "    accuracy                           0.80       705\n",
      "   macro avg       0.78      0.69      0.71       705\n",
      "weighted avg       0.80      0.80      0.79       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, final_class_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset desbalanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gráfico da Distribuição das classes em churn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Churn', data=dataset, palette='Paired', legend=False, hue='Churn')\n",
    "plt.title('Distribuição das classes em churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classificação desequilibrada é um problema comum no aprendizado de máquina, especialmente no domínio da classificação binária. Isso ocorre quando o conjunto de dados de treinamento tem uma distribuição desigual de classes, levando a um possível viés no modelo treinado. É importante abordar o desequilíbrio de classes para melhorar o desempenho do nosso modelo e garantir sua precisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modificando os Pesos na Função de Perda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A atribuição de pesos diferentes aos exemplos na função de perda pode ajudar a compensar o desequilíbrio. Isso significa dar maior importância aos exemplos da classe minoritária durante o treinamento do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`(y_train == 1).sum()`**: Este trecho conta quantas vezes a classe `1` aparece no conjunto de dados de treino. Isso é feito comparando cada elemento de `y_train` com `1` (verdadeiro onde a condição é atendida) e somando esses valores verdadeiros.\n",
    "\n",
    "**`(y_train == 0).sum()`**: Similarmente, este trecho conta quantas vezes a classe `0` aparece em `y_train`.\n",
    "\n",
    "**Divisão**: A divisão do número de exemplos da classe minoritária (1) pelo número de exemplos da classe majoritária(0) calcula um fator de peso. Esse peso será usado para equilibrar as classes, aumentando a importância das instâncias da classe minoritária durante o treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculando os pesos para cada classe\n",
    "weights = (y_train == 1).sum() / (1.0 * (y_train == 0).sum())\n",
    "\n",
    "xg_model = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.01, \n",
    "    max_depth=5,         # Quantidade de camadas, quanto mais camadas, mais complexo\n",
    "    subsample=0.7,       # Quantidade de amostras por árvore, quanto menos amostras, mais rápido\n",
    "    colsample_bytree=0.7,# Quantidade de colunas por árvore, quanto menos colunas, mais rápido\n",
    "    reg_alpha=0.01,      # Regularização L1\n",
    "    reg_lambda=1.0,      # Regularização L2\n",
    "    objective='binary:logistic',\n",
    "    random_state=42,\n",
    "    scale_pos_weight=weights\n",
    ")\n",
    "\n",
    "# Treinamento do modelo\n",
    "xg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7815602836879433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.99      0.87       511\n",
      "         1.0       0.88      0.24      0.37       194\n",
      "\n",
      "    accuracy                           0.78       705\n",
      "   macro avg       0.83      0.61      0.62       705\n",
      "weighted avg       0.80      0.78      0.73       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = xg_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step\n",
      "Ensemble Accuracy: 0.7872340425531915\n"
     ]
    }
   ],
   "source": [
    "nn_predictions = nn_model.predict(X_test)[:, 0]  # Retorna a probabilidade da classe positiva\n",
    "xgb_predictions = xg_model.predict_proba(X_test)[:, 1]  # Retorna a probabilidade da classe positiva\n",
    "\n",
    "# Média das previsões\n",
    "final_predictions = (nn_predictions + xgb_predictions) / 2\n",
    "\n",
    "# Acurácia\n",
    "final_class_predictions = (final_predictions > 0.5).astype(int)\n",
    "print(\"Ensemble Accuracy:\", accuracy_score(y_test, final_class_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.98      0.87       511\n",
      "         1.0       0.82      0.29      0.43       194\n",
      "\n",
      "    accuracy                           0.79       705\n",
      "   macro avg       0.80      0.63      0.65       705\n",
      "weighted avg       0.79      0.79      0.75       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, final_class_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise de Classe\n",
    "- **Classe 0 (Majoritária)**\n",
    "  - **Precisão**: 0.80. Isso indica que 80% das previsões para classe 0 estão corretas.\n",
    "  - **Recall**: 0.97. Significa que 97% das instâncias reais de classe 0 foram identificadas corretamente pelo modelo.\n",
    "  - **F1-Score**: 0.87. O F1-score é uma média harmônica de precisão e recall, e um valor de 0.87 sugere um bom equilíbrio entre precisão e recall para esta classe.\n",
    "  - **Suporte**: 511. Número total de casos reais da classe 0 no conjunto de teste.\n",
    "\n",
    "- **Classe 1 (Minoritária)**\n",
    "  - **Precisão**: 0.81. Isto sugere que 81% das previsões de classe 1 pelo modelo estão corretas.\n",
    "  - **Recall**: 0.35. Apenas 37% das instâncias reais de classe 1 foram identificadas corretamente, o que é bastante baixo.\n",
    "  - **F1-Score**: 0.49. Este valor mais baixo indica uma baixa eficácia do modelo em equilibrar a precisão e o recall para a classe minoritária.\n",
    "  - **Suporte**: 194. Número total de casos reais da classe 1 no conjunto de teste.\n",
    "\n",
    "### Análise Agregada\n",
    "- **Acurácia**: 0.80. Isso mostra que o modelo acertou 80% das vezes para todas as previsões feitas.\n",
    "- **Média Macro (avg)**:\n",
    "  - **Precisão**: 0.80. Média simples das precisões para ambas as classes.\n",
    "  - **Recall**: 0.66. Média simples dos recalls, afetada negativamente pelo baixo recall da classe 1.\n",
    "  - **F1-Score**: 0.68. Indica a média do F1-score, que também é puxada para baixo pela performance na classe 1.\n",
    "- **Média Ponderada (weighted avg)**:\n",
    "  - **Precisão**: 0.80. Considera o número de instâncias em cada classe, dando mais peso à classe 0.\n",
    "  - **Recall**: 0.80. Similar à precisão, ponderada pelo suporte.\n",
    "  - **F1-Score**: 0.77. F1-score ponderado que favorece a classe com mais suporte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponderar os pesos pode aumentar a precisão da classe minoritária, porém o recall e o f1-score podem ser afetados negativamente. Portanto, é importante encontrar um equilíbrio entre as métricas de avaliação para ambas as classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engenharia de Recursos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um tema comum em aprendizado de máquina é a seleção de boas características para maximizar o desempenho do modelo.\n",
    "\n",
    "Para conjuntos de dados estruturados, geralmente há dois passos para escolher um conjunto final de características:\n",
    "\n",
    "1. **Engenharia de características**: criação de novas características a partir dos dados (por exemplo, a partir do preço unitário e do volume total, talvez criar uma característica de receita total, igual ao preço vezes o volume).\n",
    "\n",
    "2. **Seleção de características**: de um conjunto de características $ p $, selecionar um subconjunto que mantenha (ou até melhore) o desempenho.\n",
    "\n",
    "Para realizar esses passos, existem considerações técnicas e empresariais. Não cobriremos as últimas: elas geralmente são específicas da aplicação e, o mais importante, dependem fortemente dos dados disponíveis.\n",
    "\n",
    "Portanto, nos concentraremos nos métodos técnicos para realizar a seleção de características: dado um conjunto de características $ x_1, \\ldots, x_p $, podemos selecionar um subconjunto $ x_1',\\ldots, x_m' $ (onde $ m $ representa \"mínimo\") que nos leve a um nível ótimo de desempenho do modelo?\n",
    "\n",
    "Uma resposta comum (antiga) é que $ p > N $ significa muitas características. Isso sempre foi o caso em estatísticas tradicionais, para métodos como regressão linear ou logística, para os quais $ p > N $ literalmente significa que o algoritmo quebra, já que a matriz $ X^T X $ não é mais invertível.\n",
    "\n",
    "Essa não é mais uma resposta satisfatória. De fato, é comum, por exemplo, em genômica, ter conjuntos de dados onde $ p \\gg N $: dados de expressão genética geralmente consideram $ p $ na ordem de 10.000 ou até 100.000 mil, enquanto $ N $ pode ser de algumas centenas (um para cada paciente no estudo, por exemplo).\n",
    "\n",
    "O mesmo pode ser visto em problemas como processamento de imagens, onde cada pixel contribui com $ O(1) $ características. À medida que os tamanhos das imagens aumentam, a contagem total de características escala quadraticamente.\n",
    "\n",
    "Para crédito, é comum ter conjuntos de dados com $ p $ entre 100-10.000 características relativas à informação financeira, comportamental e demográfica de um indivíduo. $ N $ aqui geralmente será na ordem de 100.000 - 100 milhões, ou seja, uma porcentagem da população (considerando o caso brasileiro com população total de cerca de 200 milhões)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Há sempre características inúteis.** No caso da genômica, nem todos os genes estão ativos em um determinado momento - apenas uma fração deles contribui para o fenômeno de interesse. Em uma imagem de 800x600 de um gato, apenas uma pequena parte dos pixels descreverá realmente o gato, com o restante sendo objetos que não são de interesse. Da mesma forma, por mais rica que seja a informação das características de um indivíduo, apenas algumas contribuirão para seu comportamento de crédito.\n",
    "\n",
    "**Nosso objetivo é então encontrar maneiras sistemáticas de filtrar características inúteis.**\n",
    "\n",
    "É senso comum que, se você tem poucas características, seu modelo pode simplesmente não ter informações suficientes para ter um bom desempenho.\n",
    "\n",
    "Menos óbvio é que ter muitas características também pode ser problemático. Elas podem causar perda de desempenho devido a algumas razões relacionadas:\n",
    "\n",
    "- **Sobreajuste**: quanto mais características, mais difícil será para os pontos terem vizinhos próximos (a chamada maldição da dimensionalidade); você precisará de exponencialmente mais dados para cobrir o espaço de características de maneira significativa. Seu algoritmo é propenso a apenas sobreajustar;\n",
    "\n",
    "- **Ruído**: variáveis inúteis introduzem ruído que pode afetar o treinamento;\n",
    "\n",
    "- **Considerações de tempo/espaço**: quanto mais dimensões, mais memória seu computador precisa, e mais tempo levará para treinamento, otimização de hiperparâmetros, etc.\n",
    "\n",
    "Um dos métodos para seleção de características é o algoritmo Boruta, introduzido em 2010 por Kursa e Rudnicki. Ele se provou consistentemente como uma ferramenta poderosa para seleção direta de boas características em casos com milhares de características.\n",
    "\n",
    "De maneira simples, o Boruta funciona da seguinte forma: para cada característica, digamos `x1`, o Boruta cria uma cópia `x1_copy` (chamada de *sombra* pelos autores) e então mistura aleatoriamente os valores entre todos os pontos, criando ruído.\n",
    "\n",
    "Ele então ajusta um modelo (geralmente uma floresta aleatória) implementando um método de importância de características e analisa como a importância da característica original se compara às cópias ruidosas. Se elas forem significativamente diferentes, então `x1` é considerada valiosa e mantida; se não, significa que `x1` é basicamente ruído, e é removida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso de desequilíbrio de classes, **não use o upsampling**; em vez disso, faça uma validação cruzada com um **undersampling** da classe majoritária durante a seleção de características. Para o Boruta, use um **classificador base RandomForest com pesos**: `class_weight='balanced_subsample'`, e para o modelo final (treinado com todo o conjunto de treinamento usando as características selecionadas), veja se usar `class_weight` dá um resultado melhor do que não usá-lo.\n",
    "\n",
    "O parâmetro `perc` é um parâmetro extremamente importante introduzido na versão Python. Ele basicamente define quão \"flexível\" queremos ser com nossas características: `perc=100` é o mais rigoroso, e quanto mais próximo de 0, mais flexíveis somos ao permitir que características menos importantes sejam selecionadas.\n",
    "\n",
    "Usaremos o Boruta com florestas aleatórias.\n",
    "\n",
    "Como observado pelo próprio autor (em *Boruta para quem tem pressa*, Miron B. Kursa, 21 de maio de 2020), é importante que tenhamos um número suficiente de árvores:\n",
    "> \"Para conjuntos de dados com muitas características, a configuração padrão da fonte de importância provavelmente é insuficiente; no caso particular do Random Forest, o número de árvores muitas vezes não é grande o suficiente para permitir que os escores de importância se estabilizem, o que, por sua vez, muitas vezes leva a falsos negativos e resultados instáveis.\"\n",
    "\n",
    "Isso pode ser resolvido permitindo que o próprio Boruta identifique um número ótimo de árvores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from boruta.boruta_py import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feature_boruta(X, y, \n",
    "                         perc=100,\n",
    "                         alpha=0.05,\n",
    "                         max_iter=100,\n",
    "                         max_depth=7,\n",
    "                         n_estimators='auto',\n",
    "                         n_jobs=1):\n",
    "\n",
    "    X_is_df = isinstance(X, pd.DataFrame)\n",
    "    y_is_df = isinstance(y, pd.Series)\n",
    "        \n",
    "    selector = BorutaPy(\n",
    "            estimator=RandomForestClassifier(n_estimators=100, max_depth=max_depth, n_jobs=n_jobs),\n",
    "            n_estimators=n_estimators,\n",
    "            perc=perc,      \n",
    "            alpha=alpha,    \n",
    "            max_iter=max_iter,\n",
    "            random_state=1,\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "    # boruta needs a numpy array, not a dataframe\n",
    "    X_train = X.values if X_is_df else X\n",
    "    y_train = y.values if y_is_df else y\n",
    "\n",
    "    selector.fit(X_train, y_train) \n",
    "        \n",
    "    if X_is_df:\n",
    "        columns = X.columns\n",
    "        return sorted(np.array(columns)[selector.support_.tolist()])\n",
    "    else:\n",
    "        return sorted(selector.support_.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m \u001b[43mselect_feature_boruta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m selected_features\n",
      "Cell \u001b[1;32mIn [29], line 26\u001b[0m, in \u001b[0;36mselect_feature_boruta\u001b[1;34m(X, y, perc, alpha, max_iter, max_depth, n_estimators, n_jobs)\u001b[0m\n\u001b[0;32m     23\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mif\u001b[39;00m X_is_df \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m     24\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mif\u001b[39;00m y_is_df \u001b[38;5;28;01melse\u001b[39;00m y\n\u001b[1;32m---> 26\u001b[0m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_is_df:\n\u001b[0;32m     29\u001b[0m     columns \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\boruta\\boruta_py.py:201\u001b[0m, in \u001b[0;36mBorutaPy.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m    Fits the Boruta feature selection with the provided estimator.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m        The target values.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\boruta\\boruta_py.py:260\u001b[0m, in \u001b[0;36mBorutaPy._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    255\u001b[0m _iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# holds the decision about each feature:\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# 0  - default state = tentative in original code\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# 1  - accepted in original code\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# -1 - rejected in original code\u001b[39;00m\n\u001b[1;32m--> 260\u001b[0m dec_reg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_feat, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# counts how many times a given feature was more important than\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# the best of the shadow features\u001b[39;00m\n\u001b[0;32m    263\u001b[0m hit_reg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_feat, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "selected_features = select_feature_boruta(X_train, y_train, n_jobs=10)\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
